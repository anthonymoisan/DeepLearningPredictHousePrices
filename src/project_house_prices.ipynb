{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "project_house_prices.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "30px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anthonymoisan/DeepLearningPredictHousePrices/blob/master/src/project_house_prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lFEUgE1i6K3w"
      },
      "source": [
        "# Description du projet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T_skvWIs6K30"
      },
      "source": [
        "Le projet consiste à prévoir le prix de maisons en fonction d'un certain nombre de caractéristiques. Ce projet est issu d'un défi Kaggle que l'on peut retrouver [ici](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data \"Link to Kaggle\").\n",
        "\n",
        "L'objectif de ce projet sera :\n",
        "* de comprendre les variables explicatives et la variable cible en faisant une analyse exploratoire des données\n",
        "* de définir un premier modèle qui sera dans le cas présent une régression linéaire\n",
        "* de mettre en place un réseau de neurones\n",
        "* de faire une analyse comparative entre les deux modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "USNdKzNc6K32"
      },
      "source": [
        "# Type de problème\n",
        "On est typiquement dans une problématique de régression dans le cas d'un apprentissage supervisé."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZLT5e_yl6K34"
      },
      "source": [
        "# Librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-23T21:07:13.585997Z",
          "start_time": "2018-01-23T21:07:11.883063Z"
        },
        "colab_type": "code",
        "id": "DRmOV3lP6K35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "280b2b81-7304-41da-e5d9-4d022e4e572b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib \n",
        "\n",
        "#Les librairies propres à Tensorflow ou Scikit-Learn seront importées au moment de leur utilisation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using matplotlib backend: agg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HhNyIA0R6K3-"
      },
      "source": [
        "# Lecture du jeu de données\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DsZ7Yktk6K3_"
      },
      "source": [
        "## Taille du jeu de données\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-23T21:08:16.102718Z",
          "start_time": "2018-01-23T21:08:16.035614Z"
        },
        "colab_type": "code",
        "id": "BNiNKe1B6K4B",
        "outputId": "06b9893e-0157-4c2f-fd36-282b794e1ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/anthonymoisan/DeepLearningPredictHousePrices/master/input/train.csv\")\n",
        "print(\"taille du jeu de donnees :\", df.shape)\n",
        "df.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taille du jeu de donnees : (1460, 81)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>50</td>\n",
              "      <td>RL</td>\n",
              "      <td>85.0</td>\n",
              "      <td>14115</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Mitchel</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1.5Fin</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1993</td>\n",
              "      <td>1995</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Wood</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>732</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>796</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>796</td>\n",
              "      <td>566</td>\n",
              "      <td>0</td>\n",
              "      <td>1362</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>2</td>\n",
              "      <td>480</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>320</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>700</td>\n",
              "      <td>10</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>75.0</td>\n",
              "      <td>10084</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Somerst</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2004</td>\n",
              "      <td>2005</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>Stone</td>\n",
              "      <td>186.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Ex</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>1369</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>317</td>\n",
              "      <td>1686</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1694</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1694</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>636</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>255</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10382</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NWAmes</td>\n",
              "      <td>PosN</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1973</td>\n",
              "      <td>1973</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>Stone</td>\n",
              "      <td>240.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>859</td>\n",
              "      <td>BLQ</td>\n",
              "      <td>32</td>\n",
              "      <td>216</td>\n",
              "      <td>1107</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1107</td>\n",
              "      <td>983</td>\n",
              "      <td>0</td>\n",
              "      <td>2090</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>2</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1973.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>484</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>235</td>\n",
              "      <td>204</td>\n",
              "      <td>228</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Shed</td>\n",
              "      <td>350</td>\n",
              "      <td>11</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>50</td>\n",
              "      <td>RM</td>\n",
              "      <td>51.0</td>\n",
              "      <td>6120</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>OldTown</td>\n",
              "      <td>Artery</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1.5Fin</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1931</td>\n",
              "      <td>1950</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>952</td>\n",
              "      <td>952</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>FuseF</td>\n",
              "      <td>1022</td>\n",
              "      <td>752</td>\n",
              "      <td>0</td>\n",
              "      <td>1774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>TA</td>\n",
              "      <td>8</td>\n",
              "      <td>Min1</td>\n",
              "      <td>2</td>\n",
              "      <td>TA</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1931.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>2</td>\n",
              "      <td>468</td>\n",
              "      <td>Fa</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>205</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>190</td>\n",
              "      <td>RL</td>\n",
              "      <td>50.0</td>\n",
              "      <td>7420</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>BrkSide</td>\n",
              "      <td>Artery</td>\n",
              "      <td>Artery</td>\n",
              "      <td>2fmCon</td>\n",
              "      <td>1.5Unf</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1939</td>\n",
              "      <td>1950</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>851</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>991</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1077</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1077</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>TA</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>2</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1939.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1</td>\n",
              "      <td>205</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>118000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "5   6          50       RL  ...        WD         Normal    143000\n",
              "6   7          20       RL  ...        WD         Normal    307000\n",
              "7   8          60       RL  ...        WD         Normal    200000\n",
              "8   9          50       RM  ...        WD        Abnorml    129900\n",
              "9  10         190       RL  ...        WD         Normal    118000\n",
              "\n",
              "[10 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W-mZ709d6K4H"
      },
      "source": [
        "On regarde les informations assez rapidement sur les variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v-hG6uBE6K4I",
        "outputId": "009d6758-6536-4ea6-df81-480486125408",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            "Id               1460 non-null int64\n",
            "MSSubClass       1460 non-null int64\n",
            "MSZoning         1460 non-null object\n",
            "LotFrontage      1201 non-null float64\n",
            "LotArea          1460 non-null int64\n",
            "Street           1460 non-null object\n",
            "Alley            91 non-null object\n",
            "LotShape         1460 non-null object\n",
            "LandContour      1460 non-null object\n",
            "Utilities        1460 non-null object\n",
            "LotConfig        1460 non-null object\n",
            "LandSlope        1460 non-null object\n",
            "Neighborhood     1460 non-null object\n",
            "Condition1       1460 non-null object\n",
            "Condition2       1460 non-null object\n",
            "BldgType         1460 non-null object\n",
            "HouseStyle       1460 non-null object\n",
            "OverallQual      1460 non-null int64\n",
            "OverallCond      1460 non-null int64\n",
            "YearBuilt        1460 non-null int64\n",
            "YearRemodAdd     1460 non-null int64\n",
            "RoofStyle        1460 non-null object\n",
            "RoofMatl         1460 non-null object\n",
            "Exterior1st      1460 non-null object\n",
            "Exterior2nd      1460 non-null object\n",
            "MasVnrType       1452 non-null object\n",
            "MasVnrArea       1452 non-null float64\n",
            "ExterQual        1460 non-null object\n",
            "ExterCond        1460 non-null object\n",
            "Foundation       1460 non-null object\n",
            "BsmtQual         1423 non-null object\n",
            "BsmtCond         1423 non-null object\n",
            "BsmtExposure     1422 non-null object\n",
            "BsmtFinType1     1423 non-null object\n",
            "BsmtFinSF1       1460 non-null int64\n",
            "BsmtFinType2     1422 non-null object\n",
            "BsmtFinSF2       1460 non-null int64\n",
            "BsmtUnfSF        1460 non-null int64\n",
            "TotalBsmtSF      1460 non-null int64\n",
            "Heating          1460 non-null object\n",
            "HeatingQC        1460 non-null object\n",
            "CentralAir       1460 non-null object\n",
            "Electrical       1459 non-null object\n",
            "1stFlrSF         1460 non-null int64\n",
            "2ndFlrSF         1460 non-null int64\n",
            "LowQualFinSF     1460 non-null int64\n",
            "GrLivArea        1460 non-null int64\n",
            "BsmtFullBath     1460 non-null int64\n",
            "BsmtHalfBath     1460 non-null int64\n",
            "FullBath         1460 non-null int64\n",
            "HalfBath         1460 non-null int64\n",
            "BedroomAbvGr     1460 non-null int64\n",
            "KitchenAbvGr     1460 non-null int64\n",
            "KitchenQual      1460 non-null object\n",
            "TotRmsAbvGrd     1460 non-null int64\n",
            "Functional       1460 non-null object\n",
            "Fireplaces       1460 non-null int64\n",
            "FireplaceQu      770 non-null object\n",
            "GarageType       1379 non-null object\n",
            "GarageYrBlt      1379 non-null float64\n",
            "GarageFinish     1379 non-null object\n",
            "GarageCars       1460 non-null int64\n",
            "GarageArea       1460 non-null int64\n",
            "GarageQual       1379 non-null object\n",
            "GarageCond       1379 non-null object\n",
            "PavedDrive       1460 non-null object\n",
            "WoodDeckSF       1460 non-null int64\n",
            "OpenPorchSF      1460 non-null int64\n",
            "EnclosedPorch    1460 non-null int64\n",
            "3SsnPorch        1460 non-null int64\n",
            "ScreenPorch      1460 non-null int64\n",
            "PoolArea         1460 non-null int64\n",
            "PoolQC           7 non-null object\n",
            "Fence            281 non-null object\n",
            "MiscFeature      54 non-null object\n",
            "MiscVal          1460 non-null int64\n",
            "MoSold           1460 non-null int64\n",
            "YrSold           1460 non-null int64\n",
            "SaleType         1460 non-null object\n",
            "SaleCondition    1460 non-null object\n",
            "SalePrice        1460 non-null int64\n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nS26b5166K4N"
      },
      "source": [
        "## Gestion des variables catégorielles\n",
        "On regarde les valeurs uniques pour identifier les variables catégorielles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T0JHeOkh6K4O",
        "outputId": "86b8247f-1b5a-4f73-b66c-6a5e788afa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for colname, serie in df.iteritems():\n",
        "    print(colname + \" has \" + str(serie.drop_duplicates().shape[0]) + \" unique values.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id has 1460 unique values.\n",
            "MSSubClass has 15 unique values.\n",
            "MSZoning has 5 unique values.\n",
            "LotFrontage has 111 unique values.\n",
            "LotArea has 1073 unique values.\n",
            "Street has 2 unique values.\n",
            "Alley has 3 unique values.\n",
            "LotShape has 4 unique values.\n",
            "LandContour has 4 unique values.\n",
            "Utilities has 2 unique values.\n",
            "LotConfig has 5 unique values.\n",
            "LandSlope has 3 unique values.\n",
            "Neighborhood has 25 unique values.\n",
            "Condition1 has 9 unique values.\n",
            "Condition2 has 8 unique values.\n",
            "BldgType has 5 unique values.\n",
            "HouseStyle has 8 unique values.\n",
            "OverallQual has 10 unique values.\n",
            "OverallCond has 9 unique values.\n",
            "YearBuilt has 112 unique values.\n",
            "YearRemodAdd has 61 unique values.\n",
            "RoofStyle has 6 unique values.\n",
            "RoofMatl has 8 unique values.\n",
            "Exterior1st has 15 unique values.\n",
            "Exterior2nd has 16 unique values.\n",
            "MasVnrType has 5 unique values.\n",
            "MasVnrArea has 328 unique values.\n",
            "ExterQual has 4 unique values.\n",
            "ExterCond has 5 unique values.\n",
            "Foundation has 6 unique values.\n",
            "BsmtQual has 5 unique values.\n",
            "BsmtCond has 5 unique values.\n",
            "BsmtExposure has 5 unique values.\n",
            "BsmtFinType1 has 7 unique values.\n",
            "BsmtFinSF1 has 637 unique values.\n",
            "BsmtFinType2 has 7 unique values.\n",
            "BsmtFinSF2 has 144 unique values.\n",
            "BsmtUnfSF has 780 unique values.\n",
            "TotalBsmtSF has 721 unique values.\n",
            "Heating has 6 unique values.\n",
            "HeatingQC has 5 unique values.\n",
            "CentralAir has 2 unique values.\n",
            "Electrical has 6 unique values.\n",
            "1stFlrSF has 753 unique values.\n",
            "2ndFlrSF has 417 unique values.\n",
            "LowQualFinSF has 24 unique values.\n",
            "GrLivArea has 861 unique values.\n",
            "BsmtFullBath has 4 unique values.\n",
            "BsmtHalfBath has 3 unique values.\n",
            "FullBath has 4 unique values.\n",
            "HalfBath has 3 unique values.\n",
            "BedroomAbvGr has 8 unique values.\n",
            "KitchenAbvGr has 4 unique values.\n",
            "KitchenQual has 4 unique values.\n",
            "TotRmsAbvGrd has 12 unique values.\n",
            "Functional has 7 unique values.\n",
            "Fireplaces has 4 unique values.\n",
            "FireplaceQu has 6 unique values.\n",
            "GarageType has 7 unique values.\n",
            "GarageYrBlt has 98 unique values.\n",
            "GarageFinish has 4 unique values.\n",
            "GarageCars has 5 unique values.\n",
            "GarageArea has 441 unique values.\n",
            "GarageQual has 6 unique values.\n",
            "GarageCond has 6 unique values.\n",
            "PavedDrive has 3 unique values.\n",
            "WoodDeckSF has 274 unique values.\n",
            "OpenPorchSF has 202 unique values.\n",
            "EnclosedPorch has 120 unique values.\n",
            "3SsnPorch has 20 unique values.\n",
            "ScreenPorch has 76 unique values.\n",
            "PoolArea has 8 unique values.\n",
            "PoolQC has 4 unique values.\n",
            "Fence has 5 unique values.\n",
            "MiscFeature has 5 unique values.\n",
            "MiscVal has 21 unique values.\n",
            "MoSold has 12 unique values.\n",
            "YrSold has 5 unique values.\n",
            "SaleType has 9 unique values.\n",
            "SaleCondition has 6 unique values.\n",
            "SalePrice has 663 unique values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AGPtWAfG6K4Y"
      },
      "source": [
        "A la vue du fichier de description, qui est aussi confirmée par le nombre de modalités, un certain nombre de variables peuvent être redéfinies en variables catégorielles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "enau5XXG6K4Z",
        "outputId": "8dbf1636-745e-4620-e6f6-0fdc0c9292c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "dictMSSubClass = {\n",
        "20: '1-STORY 1946 & NEWER ALL STYLES',\n",
        "30: '1-STORY 1945 & OLDER',\n",
        "40: '1-STORY W/FINISHED ATTIC ALL AGES',\n",
        "45: '1-1/2 STORY - UNFINISHED ALL AGES',\n",
        "50: '1-1/2 STORY FINISHED ALL AGES',\n",
        "60: '2-STORY 1946 & NEWER',\n",
        "70: '2-STORY 1945 & OLDER',\n",
        "75: '2-1/2 STORY ALL AGES',\n",
        "80: 'SPLIT OR MULTI-LEVEL',\n",
        "85: 'SPLIT FOYER',\n",
        "90: 'DUPLEX - ALL STYLES AND AGES',\n",
        "120: '1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n",
        "150: '1-1/2 STORY PUD - ALL AGES',\n",
        "160: '2-STORY PUD - 1946 & NEWER',\n",
        "180: 'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n",
        "190: '2 FAMILY CONVERSION - ALL STYLES AND AGES'}\n",
        "\"\"\"df[\"MSSubClass\"] = pd.Categorical(df[\"MSSubClass\"], ordered=False).rename_categories(dictMSSubClass)\"\"\"\n",
        "\n",
        "dictMSZoning = {\n",
        "'A': 'Agriculture',\n",
        "'C': 'Commercial',\n",
        "'FV': 'Floating Village Residential',\n",
        "'I': 'Industrial',\n",
        "'RH': 'Residential High Density',\n",
        "'RL': 'Residential Low Density',\n",
        "'RP': 'Residential Low Density Park', \n",
        "'RM': 'Residential Medium Density'\n",
        "}\n",
        "\"\"\"df[\"MSZoning\"] = pd.Categorical(df[\"MSZoning\"], ordered=False).rename_categories(dictMSZoning)\"\"\"\n",
        "\n",
        "\"\"\"df[\"Street\"] = pd.Categorical(df[\"Street\"], ordered=False).rename_categories({'Grvl':'Gravel','Pave':'Paved'})\n",
        "\n",
        "df[\"Alley\"].fillna('No alley access', inplace = True)\n",
        "df[\"Alley\"] = pd.Categorical(df[\"Alley\"], ordered=False).rename_categories({'Grvl':'Gravel','Pave':'Paved'})\n",
        "\"\"\"\n",
        "\"\"\"df[\"LotShape\"] = pd.Categorical(df[\"LotShape\"], ordered=False).rename_categories({'Reg':'Regular', 'IR1':'Slightly irregular', 'IR2': 'Moderately Irregular', 'IR3':'Irregular'})\"\"\"\n",
        "\n",
        "\"\"\"df[\"LandContour\"] = pd.Categorical(df[\"LandContour\"], ordered=False).rename_categories({'Lvl':'Near Flat/Level','Bnk':'Banked - Quick and significant rise from street grade to building','HLS':'Hillside - Significant slope from side to side','Low':'Depression'})\"\"\"\n",
        "\n",
        "\"\"\"df[\"Utilities\"] = pd.Categorical(df[\"Utilities\"], ordered=False).rename_categories({'AllPub':'All public Utilities (E,G,W,& S)','NoSewr':'Electricity, Gas, and Water (Septic Tank)','NoSeWa':'Electricity and Gas Only','ELO':'Electricity only'})\"\"\"\n",
        "\n",
        "\"\"\"df[\"LotConfig\"] = pd.Categorical(df[\"LotConfig\"], ordered=False).rename_categories({'Inside':'Inside lot','Corner':'Corner lot','CulDSac':'Cul-de-sac','FR2':'Frontage on 2 sides of property','FR3':'Frontage on 3 sides of property'})\"\"\"\n",
        "\n",
        "\"\"\"df[\"LandSlope\"] = pd.Categorical(df[\"LandSlope\"], ordered=False).rename_categories({'Gtl': 'Gentle slope','Mod':'Moderate Slope','Sev':'Severe Slope'})\"\"\"\n",
        "\n",
        "dictNeigh = {\n",
        "'Blmngtn':'Bloomington Heights',\n",
        "'Blueste':'Bluestem',\n",
        "'BrDale':'Briardale',\n",
        "'BrkSide':'Brookside',\n",
        "'ClearCr':'Clear Creek',\n",
        "'CollgCr':'College Creek',\n",
        "'Crawfor':'Crawford',\n",
        "'Edwards':'Edwards',\n",
        "'Gilbert':'Gilbert',\n",
        "'IDOTRR':'Iowa DOT and Rail Road',\n",
        "'MeadowV':'Meadow Village',\n",
        "'Mitchel':'Mitchell',\n",
        "'Names':'North Ames',\n",
        "'NoRidge':'Northridge',\n",
        "'NPkVill':'Northpark Villa',\n",
        "'NridgHt':'Northridge Heights',\n",
        "'NWAmes':'Northwest Ames',\n",
        "'OldTown':'Old Town',\n",
        "'SWISU':'South & West of Iowa State University',\n",
        "'Sawyer':'Sawyer',\n",
        "'SawyerW':'Sawyer West',\n",
        "'Somerst':'Somerset',\n",
        "'StoneBr':'Stone Brook',\n",
        "'Timber':'Timberland',\n",
        "'Veenker':'Veenker',\n",
        "}\n",
        "\"\"\"df[\"Neighborhood\"] = pd.Categorical(df[\"Neighborhood\"], ordered=False).rename_categories(dictNeigh)\"\"\"\n",
        "\n",
        "dictCondition = {\n",
        "'Artery':'Adjacent to arterial street',\n",
        "'Feedr':'Adjacent to feeder street',\n",
        "'Norm':'Normal',\n",
        "'RRNn':'Within 200 of North-South Railroad',\n",
        "'RRAn':'Adjacent to North-South Railroad',\n",
        "'PosN':'Near positive off-site feature--park, greenbelt, etc.',\n",
        "'PosA': 'Adjacent to postive off-site feature',\n",
        "'RRNe' :'Within 200 of East-West Railroad',\n",
        "'RRAe': 'Adjacent to East-West Railroad' }\n",
        "\"\"\"df[\"Condition1\"] = pd.Categorical(df[\"Condition1\"], ordered=False).rename_categories(dictCondition)\"\"\"\n",
        "\n",
        "\"\"\"df[\"Condition2\"] = pd.Categorical(df[\"Condition2\"], ordered=False).rename_categories(dictCondition)\"\"\"\n",
        "\n",
        "dictTypeDwelling = {\n",
        "'1Fam':'Single-family Detached',\n",
        "'2FmCon': 'Two-family Conversion; originally built as one-family dwelling',\n",
        "'Duplx':'Duplex',\n",
        "'TwnhsE':'Townhouse End Unit',\n",
        "'TwnhsI':'Townhouse Inside Unit'}\n",
        "\"\"\"df[\"BldgType\"] = pd.Categorical(df[\"BldgType\"], ordered=False).rename_categories(dictTypeDwelling)\"\"\"\n",
        "\n",
        "dictSytleDwelling = {\n",
        "'1Story':'One story',\n",
        "'1.5Fin':'One and one-half story: 2nd level finished',\n",
        "'1.5Unf':'One and one-half story: 2nd level unfinished',\n",
        "'2Story':'Two story',\n",
        "'2.5Fin':'Two and one-half story: 2nd level finished',\n",
        "'2.5Unf':'Two and one-half story: 2nd level unfinished',\n",
        "'SFoyer': 'Split Foyer',\n",
        "'SLvl': 'Split Level'}\n",
        "\"\"\"df[\"HouseStyle\"] = pd.Categorical(df[\"HouseStyle\"], ordered=False).rename_categories(dictSytleDwelling)\"\"\"\n",
        "\n",
        "dictOverallQual = {\n",
        "10:'Very Excellent',\n",
        "9:'Excellent',\n",
        "8:'Very Good',\n",
        "7:'Good',\n",
        "6:'Above Average',\n",
        "5:'Average',\n",
        "4:'Below Average',\n",
        "3:'Fair',\n",
        "2:'Poor',\n",
        "1:'Very Poor'}\n",
        "\"\"\"df[\"OverallQual\"] = pd.Categorical(df[\"OverallQual\"], ordered=True).rename_categories(dictOverallQual)\"\"\"\n",
        "\"\"\"df[\"OverallCond\"] = pd.Categorical(df[\"OverallCond\"], ordered=True).rename_categories(dictOverallQual)\"\"\"\n",
        "\n",
        "dictRoofStyle = {\n",
        "'Flat':'Flat',\n",
        "'Gable':'Gable',\n",
        "'Gambrel':'Gabrel (Barn)',\n",
        "'Hip':'Hip',\n",
        "'Mansard':'Mansard',\n",
        "'Shed':'Shed'}\n",
        "\"\"\"df[\"RoofStyle\"] = pd.Categorical(df[\"RoofStyle\"], ordered=False).rename_categories(dictRoofStyle)\"\"\"\n",
        "    \n",
        "dictRoofMatl = {\n",
        "'ClyTile': 'Clay or Tile',\n",
        "'CompShg': 'Standard (Composite) Shingle',\n",
        "'Membran': 'Membrane',\n",
        "'Metal': 'Metal',\n",
        "'Roll': 'Roll',\n",
        "'Tar&Grv': 'Gravel & Tar',\n",
        "'WdShake': 'Wood Shakes',\n",
        "'WdShngl': 'Wood Shingles'\n",
        "}\n",
        "\"\"\"df[\"RoofMatl\"] = pd.Categorical(df[\"RoofMatl\"], ordered=False).rename_categories(dictRoofMatl)\"\"\"\n",
        "\n",
        "\n",
        "dictExterior = {\n",
        "'AsbShng': 'Asbestos Shingles',\n",
        "'AsphShn': 'Asphalt Shingles',\n",
        "'BrkComm': 'Brick Common',\n",
        "'BrkFace': 'Brick Face',\n",
        "'CBlock': 'Cinder Block',\n",
        "'CemntBd': 'Cement Board',\n",
        "'HdBoard': 'Hard Board',\n",
        "'ImStucc': 'Imitation Stucco',\n",
        "'MetalSd': 'Metal Siding',\n",
        "'Other': 'Other',\n",
        "'Plywood': 'Plywood',\n",
        "'PreCast': 'PreCast',\n",
        "'Stone': 'Stone',\n",
        "'Stucco': 'Stucco',\n",
        "'VinylSd': 'Vinyl Siding',\n",
        "'Wd Sdng': 'Wood Siding',\n",
        "'WdShing': 'Wood Shingles'\n",
        "}\n",
        "\n",
        "\"\"\"df[\"Exterior1st\"] = pd.Categorical(df[\"Exterior1st\"], ordered=False).rename_categories(dictExterior)\n",
        "df[\"Exterior2nd\"] = pd.Categorical(df[\"Exterior2nd\"], ordered=False).rename_categories(dictExterior)\"\"\"\n",
        "\n",
        "dictMasVnrType = {\n",
        "'BrkCmn':'Brick Common',\n",
        "'BrkFace':'Brick Face',\n",
        "'CBlock':'Cinder Block',\n",
        "'None':'None',\n",
        "'Stone': 'Stone'}\n",
        "\"\"\"df[\"MasVnrType\"] = pd.Categorical(df[\"MasVnrType\"], ordered=False).rename_categories(dictMasVnrType)\"\"\"\n",
        "\n",
        "dictExterQual = {\n",
        "'Ex':'Excellent',\n",
        "'Gd':'Good',\n",
        "'TA':'Average/Typical',\n",
        "'Fa':'Fair',\n",
        "'Po':'Poor'}\n",
        "\"\"\"df[\"ExterQual\"] = pd.Categorical(df[\"ExterQual\"], ordered=True).rename_categories(dictExterQual)\n",
        "df[\"ExterCond\"] = pd.Categorical(df[\"ExterCond\"], ordered=True).rename_categories(dictExterQual)\"\"\"\n",
        "\n",
        "dictFoundation = {\n",
        "'BrkTil':'Brick & Tile',\n",
        "'CBlock': 'Cinder Block',\n",
        "'PConc': 'Poured Contrete',\n",
        "'Slab':'Slab',\n",
        "'Stone':'Stone',\n",
        "'Wood':'Wood'}\n",
        "\"\"\"df[\"Foundation\"] = pd.Categorical(df[\"Foundation\"], ordered=False).rename_categories(dictFoundation)\"\"\"\n",
        "\n",
        "dictBsmtQual = {\n",
        "'Ex':'Excellent (100+ inches)',\n",
        "'Gd':'Good (90-99 inches)',\n",
        "'TA':'Typical (80-89 inches)',\n",
        "'Fa':'Fair (70-79 inches)',\n",
        "'Po':'Poor (<70 inches'}\n",
        "\"\"\"df[\"BsmtQual\"] = pd.Categorical(df[\"BsmtQual\"], ordered=True).rename_categories(dictBsmtQual)\"\"\"\n",
        "\n",
        "dictBsmtCond = {\n",
        "'Ex':'Excellent',\n",
        "'Gd':'Good',\n",
        "'TA':'Typical - slight dampness allowed',\n",
        "'Fa':'Fair - dampness or some cracking or settling',\n",
        "'Po':'Poor - Severe cracking, settling, or wetness'}\n",
        "\"\"\"df[\"BsmtCond\"] = pd.Categorical(df[\"BsmtCond\"], ordered=True).rename_categories(dictBsmtCond)\"\"\"\n",
        "\n",
        "dictBsmtExposure = {\n",
        "'Gd':'Good Exposure',\n",
        "'Av':'Average Exposure (split levels or foyers typically score average or above)',\n",
        "'Mn':'Mimimum Exposure',\n",
        "'No': 'No Exposure'}\n",
        "\"\"\"df[\"BsmtExposure\"] = pd.Categorical(df[\"BsmtExposure\"], ordered=True).rename_categories(dictBsmtExposure)\"\"\"\n",
        "\n",
        "dictBsmtFinType = {\n",
        "'GLQ':'Good Living Quarters',\n",
        "'ALQ':'Average Living Quarters',\n",
        "'BLQ':'Below Average Living Quarters',\n",
        "'Rec':'Average Rec Room',\n",
        "'LwQ':'Low Quality',\n",
        "'Unf':'Unfinshed'}\n",
        "\"\"\"df[\"BsmtFinType1\"] = pd.Categorical(df[\"BsmtFinType1\"], ordered=True).rename_categories(dictBsmtFinType)\n",
        "df[\"BsmtFinType2\"] = pd.Categorical(df[\"BsmtFinType2\"], ordered=True).rename_categories(dictBsmtFinType)\"\"\"\n",
        "\n",
        "dictHeating = {\n",
        "'Floor':'Floor Furnace',\n",
        "'GasA':'Gas forced warm air furnace',\n",
        "'GasW':'Gas hot water or steam heat',\n",
        "'Grav':'Gravity furnace',\n",
        "'OthW':'Hot water or steam heat other than gas',\n",
        "'Wall':'Wall furnace'}\n",
        "\"\"\"df[\"Heating\"] = pd.Categorical(df[\"Heating\"], ordered=False).rename_categories(dictHeating)\"\"\"\n",
        "\n",
        "dictHeatingQC = {\n",
        "'Ex':'Excellent',\n",
        "'Gd':'Good',\n",
        "'TA':'Average/Typical',\n",
        "'Fa':'Fair',\n",
        "'Po':'Poor'}\n",
        "\"\"\"df[\"HeatingQC\"] = pd.Categorical(df[\"HeatingQC\"], ordered=True).rename_categories(dictHeatingQC)\"\"\"\n",
        "\n",
        "\"\"\"df[\"CentralAir\"] = pd.Categorical(df[\"CentralAir\"], ordered=False).rename_categories({'N': 'No', 'Y':'Yes'})\"\"\"\n",
        "\n",
        "dictElectrical = {\n",
        "'SBrkr':'Standard Circuit Breakers & Romex',\n",
        "'FuseA': 'Fuse Box over 60 AMP and all Romex wiring (Average)',\n",
        "'FuseF': '60 AMP Fuse Box and mostly Romex wiring (Fair)',\n",
        "'FuseP': '60 AMP Fuse Box and mostly knob & tube wiring (poor)',\n",
        "'Mix':'Mixed'}\n",
        "\"\"\"df[\"Electrical\"] = pd.Categorical(df[\"Electrical\"], ordered=False).rename_categories(dictElectrical)\"\"\"\n",
        "\n",
        "dictKitchenQual = {\n",
        "'Ex':'Excellent',\n",
        "'Gd':'Good',\n",
        "'TA':'Typical/Average',\n",
        "'Fa':'Fair',\n",
        "'Po':'Poor'}\n",
        "\"\"\"df[\"KitchenQual\"] = pd.Categorical(df[\"KitchenQual\"], ordered=True).rename_categories(dictKitchenQual)\"\"\"\n",
        "\n",
        "dictFunctional = {\n",
        "'Typ':'Typical Functionality',\n",
        "'Min1':'Minor Deductions 1',\n",
        "'Min2':'Minor Deductions 2',\n",
        "'Mod':'Moderate Deductions',\n",
        "'Maj1':'Major Deductions 1',\n",
        "'Maj2':'Major Deductions 2',\n",
        "'Sev':'Severely Damaged',\n",
        "'Sal':'Salvage only'}\n",
        "\"\"\"df[\"Functional\"] = pd.Categorical(df[\"Functional\"], ordered=True).rename_categories(dictFunctional)\"\"\"\n",
        "\n",
        "dictFireplaceQu = {\n",
        "'Ex':'Excellent - Exceptional Masonry Fireplace',\n",
        "'Gd':'Good - Masonry Fireplace in main level',\n",
        "'TA':'Average - Prefabricated Fireplace in main living area or Masonry Fireplace in basement',\n",
        "'Fa':'Fair - Prefabricated Fireplace in basement',\n",
        "'Po':'Poor - Ben Franklin Stove'}\n",
        "\"\"\"df[\"FireplaceQu\"] = pd.Categorical(df[\"FireplaceQu\"], ordered=True).rename_categories(dictFireplaceQu)\"\"\"\n",
        "\n",
        "dictGarageType = {\n",
        "'2Types':'More than one type of garage',\n",
        "'Attchd':'Attached to home',\n",
        "'Basment':'Basement Garage',\n",
        "'BuiltIn':'Built-In (Garage part of house - typically has room above garage)',\n",
        "'CarPort':'Car Port',\n",
        "'Detchd':'Detached from home'}\n",
        "\"\"\"df[\"GarageType\"] = pd.Categorical(df[\"GarageType\"], ordered=False).rename_categories(dictGarageType)\"\"\"\n",
        "\n",
        "dictGarageFinish = {\n",
        "'Fin':'Finished',\n",
        "'RFn':'Rough Finished',\n",
        "'Unf':'Unfinished'}\n",
        "\"\"\"df[\"GarageFinish\"] = pd.Categorical(df[\"GarageFinish\"], ordered=False).rename_categories(dictGarageFinish)\"\"\"\n",
        "\n",
        "dictGarageQual = {\n",
        "'Ex':'Excellent',\n",
        "'Gd':'Good',\n",
        "'TA':'Typical/Average',\n",
        "'Fa':'Fair',\n",
        "'Po':'Poor'}\n",
        "\"\"\"df[\"GarageQual\"] = pd.Categorical(df[\"GarageQual\"], ordered=True).rename_categories(dictGarageQual)\n",
        "df[\"GarageCond\"] = pd.Categorical(df[\"GarageCond\"], ordered=True).rename_categories(dictGarageQual)\"\"\"\n",
        "\n",
        "\"\"\"df[\"PavedDrive\"] = pd.Categorical(df[\"PavedDrive\"], ordered=False).rename_categories({'Y':'Paved','P':'Partial Pavement','N':'Dirt/Gravel'})\"\"\"\n",
        "dictPoolQC = {\n",
        "'Ex':'Excellent',\n",
        "'Gd':'Good',\n",
        "'TA':'Average/Typical',\n",
        "'Fa':'Fair'}\n",
        "\"\"\"df[\"PoolQC\"] = pd.Categorical(df[\"PoolQC\"], ordered=True).rename_categories(dictPoolQC)\"\"\"\n",
        "\n",
        "dictFence = {\n",
        "'GdPrv': 'Good Privacy',\n",
        "'MnPrv': 'Minimum Privacy',\n",
        "'GdWo': 'Good Wood',\n",
        "'MnWw': 'Minimum Wood/Wire'}\n",
        "\"\"\"df[\"Fence\"] = pd.Categorical(df[\"Fence\"], ordered=False).rename_categories(dictFence)\"\"\"\n",
        "\n",
        "dictMiscFeature = {\n",
        "'Elev':'Elevator',\n",
        "'Gar2':'2nd Garage (if not described in garage section)',\n",
        "'Othr':'Other',\n",
        "'Shed':'Shed (over 100 SF)',\n",
        "'TenC':'Tennis Court'}\n",
        "\"\"\"df[\"MiscFeature\"] = pd.Categorical(df[\"MiscFeature\"], ordered=False).rename_categories(dictMiscFeature)\"\"\"\n",
        "\n",
        "dictSaleType = {\n",
        "'WD':'Warranty Deed - Conventional',\n",
        "'CWD':'Warranty Deed - Cash',\n",
        "'VWD':'Warranty Deed - VA Loan',\n",
        "'New':'Home just constructed and sold',\n",
        "'COD':'Court Officer Deed/Estate',\n",
        "'Con':'Contract 15% Down payment regular terms',\n",
        "'ConLw':'Contract Low Down payment and low interest',\n",
        "'ConLI':'Contract Low Interest',\n",
        "'ConLD':'Contract Low Down',\n",
        "'Oth':'Other'\n",
        "}\n",
        "\"\"\"df[\"SaleType\"] = pd.Categorical(df[\"SaleType\"], ordered=False).rename_categories(dictSaleType)\"\"\"\n",
        "\n",
        "dictSaleCondition = {\n",
        "'Normal':'Normal Sale',\n",
        "'Abnorml':'Abnormal Sale -  trade, foreclosure, short sale',\n",
        "'AdjLand':'Adjoining Land Purchase',\n",
        "'Alloca':'Allocation - two linked properties with separate deeds, typically condo with a garage unit',\n",
        "'Family':'Sale between family members',\n",
        "'Partial':'Home was not completed when last assessed (associated with New Homes)'}\n",
        "\"\"\"df[\"SaleCondition\"] = pd.Categorical(df[\"SaleCondition\"], ordered=False).rename_categories(dictSaleCondition)\"\"\"\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'df[\"SaleCondition\"] = pd.Categorical(df[\"SaleCondition\"], ordered=False).rename_categories(dictSaleCondition)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZcYBBbr9JOg",
        "colab_type": "text"
      },
      "source": [
        "__**Initialement**__ : on avait décidé de remettre les noms longs des modalités mais les graphiques n'étaient plus par la suite lisibles. On s'est aussi aperçu que les modalités NA des dictionnaires n'étaient pas bien pris en compte initialement et donc on a utilisé la fonction fillna avec le code suivant :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZmitOwW9JOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DefineCategoricalVariableAndDefineNa(myDf):\n",
        "    myDf[\"MSSubClass\"] = pd.Categorical(myDf[\"MSSubClass\"], ordered=False)\n",
        "    myDf[\"MSZoning\"] = pd.Categorical(myDf[\"MSZoning\"], ordered=False)\n",
        "    myDf[\"Street\"] = pd.Categorical(myDf[\"Street\"], ordered=False).rename_categories({'Grvl':'Gravel','Pave':'Paved'})\n",
        "    myDf[\"Alley\"].fillna('No alley access', inplace = True)\n",
        "    myDf[\"Alley\"] = pd.Categorical(myDf[\"Alley\"], ordered=False).rename_categories({'Grvl':'Gravel','Pave':'Paved'})\n",
        "    myDf[\"LotShape\"] = pd.Categorical(myDf[\"LotShape\"], ordered=False)\n",
        "    myDf[\"LandContour\"] = pd.Categorical(myDf[\"LandContour\"], ordered=False)\n",
        "    myDf[\"Utilities\"] = pd.Categorical(myDf[\"Utilities\"], ordered=False)\n",
        "    myDf[\"LotConfig\"] = pd.Categorical(myDf[\"LotConfig\"], ordered=False)\n",
        "    myDf[\"LandSlope\"] = pd.Categorical(myDf[\"LandSlope\"], ordered=False)\n",
        "    myDf[\"Neighborhood\"] = pd.Categorical(myDf[\"Neighborhood\"], ordered=False)\n",
        "    myDf[\"Condition1\"] = pd.Categorical(myDf[\"Condition1\"], ordered=False)\n",
        "    myDf[\"Condition2\"] = pd.Categorical(myDf[\"Condition2\"], ordered=False)\n",
        "    myDf[\"BldgType\"] = pd.Categorical(myDf[\"BldgType\"], ordered=False)\n",
        "    myDf[\"HouseStyle\"] = pd.Categorical(myDf[\"HouseStyle\"], ordered=False)\n",
        "    myDf[\"OverallQual\"] = pd.Categorical(myDf[\"OverallQual\"], ordered=True)\n",
        "    myDf[\"OverallCond\"] = pd.Categorical(myDf[\"OverallCond\"], ordered=True)\n",
        "    myDf[\"RoofStyle\"] = pd.Categorical(myDf[\"RoofStyle\"], ordered=False)\n",
        "    myDf[\"RoofMatl\"] = pd.Categorical(myDf[\"RoofMatl\"], ordered=False)\n",
        "    myDf[\"Exterior1st\"] = pd.Categorical(myDf[\"Exterior1st\"], ordered=False)\n",
        "    myDf[\"Exterior2nd\"] = pd.Categorical(myDf[\"Exterior2nd\"], ordered=False)\n",
        "    myDf[\"MasVnrType\"] = pd.Categorical(myDf[\"MasVnrType\"], ordered=False)\n",
        "    myDf[\"ExterQual\"] = pd.Categorical(myDf[\"ExterQual\"], ordered=True)\n",
        "    myDf[\"ExterCond\"] = pd.Categorical(myDf[\"ExterCond\"], ordered=True)\n",
        "    myDf[\"Foundation\"] = pd.Categorical(myDf[\"Foundation\"], ordered=False)\n",
        "    myDf[\"BsmtQual\"].fillna(\"No Basement\", inplace=True)\n",
        "    myDf[\"BsmtQual\"] = pd.Categorical(myDf[\"BsmtQual\"], ordered=True)\n",
        "    myDf[\"BsmtCond\"].fillna(\"No Basement\", inplace=True)\n",
        "    myDf[\"BsmtCond\"] = pd.Categorical(myDf[\"BsmtCond\"], ordered=True)\n",
        "    myDf[\"BsmtExposure\"].fillna(\"No Basement\", inplace=True)\n",
        "    myDf[\"BsmtExposure\"] = pd.Categorical(myDf[\"BsmtExposure\"], ordered=True)\n",
        "    myDf[\"BsmtFinType1\"].fillna(\"No Basement\", inplace=True)\n",
        "    myDf[\"BsmtFinType2\"].fillna(\"No Basement\", inplace=True)\n",
        "    myDf[\"BsmtFinType1\"] = pd.Categorical(myDf[\"BsmtFinType1\"], ordered=True)\n",
        "    myDf[\"BsmtFinType2\"] = pd.Categorical(myDf[\"BsmtFinType2\"], ordered=True)\n",
        "    myDf[\"Heating\"] = pd.Categorical(myDf[\"Heating\"], ordered=False)\n",
        "    myDf[\"HeatingQC\"] = pd.Categorical(myDf[\"HeatingQC\"], ordered=True)\n",
        "    myDf[\"CentralAir\"] = pd.Categorical(myDf[\"CentralAir\"], ordered=False).rename_categories({'N': 'No', 'Y':'Yes'})\n",
        "    myDf[\"Electrical\"] = pd.Categorical(myDf[\"Electrical\"], ordered=False)\n",
        "    myDf[\"KitchenQual\"] = pd.Categorical(myDf[\"KitchenQual\"], ordered=True)\n",
        "    myDf[\"Functional\"] = pd.Categorical(myDf[\"Functional\"], ordered=True)\n",
        "    myDf[\"FireplaceQu\"].fillna(\"No Fireplace\", inplace=True)\n",
        "    myDf[\"FireplaceQu\"] = pd.Categorical(myDf[\"FireplaceQu\"], ordered=True)\n",
        "    myDf[\"GarageType\"].fillna(\"No Garage\", inplace=True)\n",
        "    myDf[\"GarageType\"] = pd.Categorical(myDf[\"GarageType\"], ordered=False)\n",
        "    myDf[\"GarageFinish\"].fillna(\"No Garage\", inplace=True)\n",
        "    myDf[\"GarageFinish\"] = pd.Categorical(myDf[\"GarageFinish\"], ordered=False)\n",
        "    myDf[\"GarageQual\"].fillna(\"No Garage\", inplace=True)\n",
        "    myDf[\"GarageCond\"].fillna(\"No Garage\", inplace=True)\n",
        "    myDf[\"GarageQual\"] = pd.Categorical(myDf[\"GarageQual\"], ordered=True)\n",
        "    myDf[\"GarageCond\"] = pd.Categorical(myDf[\"GarageCond\"], ordered=True)\n",
        "    myDf[\"PavedDrive\"] = pd.Categorical(myDf[\"PavedDrive\"], ordered=False).rename_categories({'Y':'Paved','P':'Partial Pavement','N':'Dirt/Gravel'})\n",
        "    myDf[\"PoolQC\"].fillna(\"No Pool\", inplace=True)\n",
        "    myDf[\"PoolQC\"] = pd.Categorical(myDf[\"PoolQC\"], ordered=True)\n",
        "    myDf[\"Fence\"].fillna(\"No Fence\", inplace = True)\n",
        "    myDf[\"Fence\"] = pd.Categorical(myDf[\"Fence\"], ordered=False)\n",
        "    myDf[\"MiscFeature\"].fillna('None', inplace = True)\n",
        "    myDf[\"MiscFeature\"] = pd.Categorical(myDf[\"MiscFeature\"], ordered=False)\n",
        "    myDf[\"SaleType\"] = pd.Categorical(myDf[\"SaleType\"], ordered=False)\n",
        "    myDf[\"SaleCondition\"] = pd.Categorical(myDf[\"SaleCondition\"], ordered=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LVtQK-wU6K4e",
        "outputId": "2d9a48ef-2712-43a2-ddbc-17d422d16b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "DefineCategoricalVariableAndDefineNa(df)\n",
        "df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            "Id               1460 non-null int64\n",
            "MSSubClass       1460 non-null category\n",
            "MSZoning         1460 non-null category\n",
            "LotFrontage      1201 non-null float64\n",
            "LotArea          1460 non-null int64\n",
            "Street           1460 non-null category\n",
            "Alley            1460 non-null category\n",
            "LotShape         1460 non-null category\n",
            "LandContour      1460 non-null category\n",
            "Utilities        1460 non-null category\n",
            "LotConfig        1460 non-null category\n",
            "LandSlope        1460 non-null category\n",
            "Neighborhood     1460 non-null category\n",
            "Condition1       1460 non-null category\n",
            "Condition2       1460 non-null category\n",
            "BldgType         1460 non-null category\n",
            "HouseStyle       1460 non-null category\n",
            "OverallQual      1460 non-null category\n",
            "OverallCond      1460 non-null category\n",
            "YearBuilt        1460 non-null int64\n",
            "YearRemodAdd     1460 non-null int64\n",
            "RoofStyle        1460 non-null category\n",
            "RoofMatl         1460 non-null category\n",
            "Exterior1st      1460 non-null category\n",
            "Exterior2nd      1460 non-null category\n",
            "MasVnrType       1452 non-null category\n",
            "MasVnrArea       1452 non-null float64\n",
            "ExterQual        1460 non-null category\n",
            "ExterCond        1460 non-null category\n",
            "Foundation       1460 non-null category\n",
            "BsmtQual         1460 non-null category\n",
            "BsmtCond         1460 non-null category\n",
            "BsmtExposure     1460 non-null category\n",
            "BsmtFinType1     1460 non-null category\n",
            "BsmtFinSF1       1460 non-null int64\n",
            "BsmtFinType2     1460 non-null category\n",
            "BsmtFinSF2       1460 non-null int64\n",
            "BsmtUnfSF        1460 non-null int64\n",
            "TotalBsmtSF      1460 non-null int64\n",
            "Heating          1460 non-null category\n",
            "HeatingQC        1460 non-null category\n",
            "CentralAir       1460 non-null category\n",
            "Electrical       1459 non-null category\n",
            "1stFlrSF         1460 non-null int64\n",
            "2ndFlrSF         1460 non-null int64\n",
            "LowQualFinSF     1460 non-null int64\n",
            "GrLivArea        1460 non-null int64\n",
            "BsmtFullBath     1460 non-null int64\n",
            "BsmtHalfBath     1460 non-null int64\n",
            "FullBath         1460 non-null int64\n",
            "HalfBath         1460 non-null int64\n",
            "BedroomAbvGr     1460 non-null int64\n",
            "KitchenAbvGr     1460 non-null int64\n",
            "KitchenQual      1460 non-null category\n",
            "TotRmsAbvGrd     1460 non-null int64\n",
            "Functional       1460 non-null category\n",
            "Fireplaces       1460 non-null int64\n",
            "FireplaceQu      1460 non-null category\n",
            "GarageType       1460 non-null category\n",
            "GarageYrBlt      1379 non-null float64\n",
            "GarageFinish     1460 non-null category\n",
            "GarageCars       1460 non-null int64\n",
            "GarageArea       1460 non-null int64\n",
            "GarageQual       1460 non-null category\n",
            "GarageCond       1460 non-null category\n",
            "PavedDrive       1460 non-null category\n",
            "WoodDeckSF       1460 non-null int64\n",
            "OpenPorchSF      1460 non-null int64\n",
            "EnclosedPorch    1460 non-null int64\n",
            "3SsnPorch        1460 non-null int64\n",
            "ScreenPorch      1460 non-null int64\n",
            "PoolArea         1460 non-null int64\n",
            "PoolQC           1460 non-null category\n",
            "Fence            1460 non-null category\n",
            "MiscFeature      1460 non-null category\n",
            "MiscVal          1460 non-null int64\n",
            "MoSold           1460 non-null int64\n",
            "YrSold           1460 non-null int64\n",
            "SaleType         1460 non-null category\n",
            "SaleCondition    1460 non-null category\n",
            "SalePrice        1460 non-null int64\n",
            "dtypes: category(46), float64(3), int64(32)\n",
            "memory usage: 477.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SfrDA-i9JOm",
        "colab_type": "text"
      },
      "source": [
        "Les données semblent correctement typées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu6JLl8D9JOn",
        "colab_type": "text"
      },
      "source": [
        "L'analyse sommaire des données permet de voir les éléments suivants :\n",
        "\n",
        "* le premier champs est un identifiant numérique\n",
        "\n",
        "![Identifiant](https://github.com/anthonymoisan/DeepLearningPredictHousePrices/blob/master/img/Identifiant.PNG?raw=1)\n",
        "\n",
        "* on a ensuite des champs permettant de caractériser **la localisation et les caractéristiques de la propriété**\n",
        "\n",
        "![Localisation](https://github.com/anthonymoisan/DeepLearningPredictHousePrices/blob/master/img/localisation.PNG?raw=1)\n",
        "\n",
        "* on a des champs définissant ensuite des **informations générales sur la construction**\n",
        "\n",
        "![Informations générales](https://github.com/anthonymoisan/DeepLearningPredictHousePrices/blob/master/img/Infos.PNG?raw=1)\n",
        "\n",
        "* on a des champs décrivant **la toiture, l'emprise au sol, le sous-sol**\n",
        "\n",
        "![Exterieur](https://github.com/anthonymoisan/DeepLearningPredictHousePrices/blob/master/img/Exterieur.PNG?raw=1)\n",
        "\n",
        "* on a des champs décrivant les **accès aux commodités** (électrique, chauffage, air conditioné...)\n",
        "\n",
        "![Commodites](https://github.com/anthonymoisan/DeepLearningPredictHousePrices/blob/master/img/commodites.PNG?raw=1)\n",
        "\n",
        "* on a des champs décrivant la **maison au-dessus du sous-sol**\n",
        "\n",
        "![Interieur](https://github.com/anthonymoisan/DeepLearningPredictHousePrices/blob/master/img/Interieur.PNG?raw=1)\n",
        "\n",
        "* on a des champs décrivant des **commodités spéciales (piscines, vérandas) et le garage**\n",
        "\n",
        "![GarageExterieur](https://github.com/anthonymoisan/DeepLearningPredictHousePrices/blob/master/img/GaragesEtExterieur.PNG?raw=1)\n",
        "\n",
        "* on a enfin des champs décrivant les **caractéristiques de la vente**\n",
        "\n",
        "![Vente](https://github.com/anthonymoisan/DeepLearningPredictHousePrices/blob/master/img/Vente.PNG?raw=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nf6RmXOM6K41"
      },
      "source": [
        "# Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "29aqqL6o6K42"
      },
      "source": [
        "## Valeurs manquantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "skPsGBzL6K44",
        "outputId": "12a6b9cd-ed9d-4fd7-9055-3d7706763c17",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "# Nombre de valeurs manquantes par variable\n",
        "total = df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>259</td>\n",
              "      <td>0.177397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <td>81</td>\n",
              "      <td>0.055479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrType</th>\n",
              "      <td>8</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrArea</th>\n",
              "      <td>8</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Electrical</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExterCond</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RoofStyle</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RoofMatl</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exterior1st</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total   Percent\n",
              "LotFrontage    259  0.177397\n",
              "GarageYrBlt     81  0.055479\n",
              "MasVnrType       8  0.005479\n",
              "MasVnrArea       8  0.005479\n",
              "Electrical       1  0.000685\n",
              "SalePrice        0  0.000000\n",
              "ExterCond        0  0.000000\n",
              "RoofStyle        0  0.000000\n",
              "RoofMatl         0  0.000000\n",
              "Exterior1st      0  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Om8zqBj46K49"
      },
      "source": [
        "On peut observer qu'il y a peu de données manquantes sur ce dataset : un petit problème avec la variable LotFrontage avec une complétion à 83%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-w6YH326K4-"
      },
      "source": [
        "## Exploration univariée\n",
        "\n",
        "### La variable cible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y272Ce0z6K5A"
      },
      "source": [
        "On va regarder la distribution de notre variable à expliquer à savoir le prix des logements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gmmx4ArJ6K5B",
        "outputId": "e43ea1b1-410d-4275-8549-49ef53ea0a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "df['SalePrice'].describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count      1460.000000\n",
              "mean     180921.195890\n",
              "std       79442.502883\n",
              "min       34900.000000\n",
              "25%      129975.000000\n",
              "50%      163000.000000\n",
              "75%      214000.000000\n",
              "max      755000.000000\n",
              "Name: SalePrice, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JpRkdr7e6K5G",
        "colab": {}
      },
      "source": [
        "df[\"SalePrice\"].hist(bins=100)\n",
        "plt.title(\"Distribution des prix des maisons\")\n",
        "plt.xlabel(\"# Prix\")\n",
        "plt.ylabel(\"Effectif\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1LLCWuu56K5L"
      },
      "source": [
        "La cible de notre modèle s'apparente à une log-normale. Elle a pour moyenne 181 K et un écart type de l'ordre de 80 K avec une plage de valeurs compris entre 35 K et 755 K."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPM3_Ynd9JOy",
        "colab_type": "text"
      },
      "source": [
        "### Les autres variables numériques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f1_o7VM9JOy",
        "colab_type": "code",
        "outputId": "6e6db982-e879-46f7-ff84-b6dbcbb8c5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "df_num = df.select_dtypes(include = ['float64', 'int64'])\n",
        "df_num = df_num.drop([\"SalePrice\", \"Id\"], axis = 1)\n",
        "df_num.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1379.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>46.549315</td>\n",
              "      <td>567.240411</td>\n",
              "      <td>1057.429452</td>\n",
              "      <td>1162.626712</td>\n",
              "      <td>346.992466</td>\n",
              "      <td>5.844521</td>\n",
              "      <td>1515.463699</td>\n",
              "      <td>0.425342</td>\n",
              "      <td>0.057534</td>\n",
              "      <td>1.565068</td>\n",
              "      <td>0.382877</td>\n",
              "      <td>2.866438</td>\n",
              "      <td>1.046575</td>\n",
              "      <td>6.517808</td>\n",
              "      <td>0.613014</td>\n",
              "      <td>1978.506164</td>\n",
              "      <td>1.767123</td>\n",
              "      <td>472.980137</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>161.319273</td>\n",
              "      <td>441.866955</td>\n",
              "      <td>438.705324</td>\n",
              "      <td>386.587738</td>\n",
              "      <td>436.528436</td>\n",
              "      <td>48.623081</td>\n",
              "      <td>525.480383</td>\n",
              "      <td>0.518911</td>\n",
              "      <td>0.238753</td>\n",
              "      <td>0.550916</td>\n",
              "      <td>0.502885</td>\n",
              "      <td>0.815778</td>\n",
              "      <td>0.220338</td>\n",
              "      <td>1.625393</td>\n",
              "      <td>0.644666</td>\n",
              "      <td>24.689725</td>\n",
              "      <td>0.747315</td>\n",
              "      <td>213.804841</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1900.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>795.750000</td>\n",
              "      <td>882.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1129.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1961.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>334.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>477.500000</td>\n",
              "      <td>991.500000</td>\n",
              "      <td>1087.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1464.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1980.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>1298.250000</td>\n",
              "      <td>1391.250000</td>\n",
              "      <td>728.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1776.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2002.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>1474.000000</td>\n",
              "      <td>2336.000000</td>\n",
              "      <td>6110.000000</td>\n",
              "      <td>4692.000000</td>\n",
              "      <td>2065.000000</td>\n",
              "      <td>572.000000</td>\n",
              "      <td>5642.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1418.000000</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       LotFrontage        LotArea  ...       MoSold       YrSold\n",
              "count  1201.000000    1460.000000  ...  1460.000000  1460.000000\n",
              "mean     70.049958   10516.828082  ...     6.321918  2007.815753\n",
              "std      24.284752    9981.264932  ...     2.703626     1.328095\n",
              "min      21.000000    1300.000000  ...     1.000000  2006.000000\n",
              "25%      59.000000    7553.500000  ...     5.000000  2007.000000\n",
              "50%      69.000000    9478.500000  ...     6.000000  2008.000000\n",
              "75%      80.000000   11601.500000  ...     8.000000  2009.000000\n",
              "max     313.000000  215245.000000  ...    12.000000  2010.000000\n",
              "\n",
              "[8 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HL5t6jsH6K5M",
        "outputId": "07838850-2879-49e0-bb72-1f083c7179d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "source": [
        "df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c381f7b8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c3776080>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c37a41d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c3754320>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c3705470>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c36b95c0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c366c710>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c36a1b38>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c36a1b70>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c36106a0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c35c0c50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c357f240>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c352e7f0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c3561da0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c351e390>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c34d0940>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c3481ef0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c34404e0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c33eea90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c33af080>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c33de630>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c338fbe0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c334c1d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c32fe780>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c32aed30>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c326e320>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c329d8d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c3252e80>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c320e470>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c31bfa20>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c3170fd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c312d5c0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c315eb70>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c311c160>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c30cd710>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc7c3080cc0>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r9tVJrIO6K5R"
      },
      "source": [
        "On peut observer :\n",
        "* sur la **la localisation et les caractéristiques de la propriété**\n",
        "  * que les variables LotFrontage et LotArea ont une distribution de type LogNormal comme la cible\n",
        "  * que la variable LotArea a des valeurs extrêmes supérieures\n",
        "* sur les **informations générales sur la construction**\n",
        "  * des années de construction entre 1872 et 2010\n",
        "  * des années de rénovation entre 1950 et 2010\n",
        "* sur la **la toiture, l'emprise au sol, le sous-sol**\n",
        "  * que la valeur surface de maçonnerie a des valeurs extrêmes de même que les variables BsmtFinSF1 et BsmtFinSF2 \n",
        "  * que les variables TotalBsmtSF et BsmtUnfSF ont aussi une distribution de type LogNormal\n",
        "* sur les caractéristiques de la **maison au-dessus du sous-sol**\n",
        "  * que la surface habitable a une distribution de type LogNormal\n",
        "  * que la majorité des maisons ont un étage\n",
        "  * que le nombre de chambres le plus important en terme de modalités est 3\n",
        "  * des informations sur les salles de bains, douches, cheminées avec des modalités comprises entre 0 et 3\n",
        "* sur les **commodités spéciales (piscines, vérandas) et le garage**\n",
        "  * 2 places de parking est la modalité la plus présente\n",
        "  * une surface du garage qui suit aussi une loi normale\n",
        "* sur les **caractéristiques des ventes** :\n",
        "  * que les années de vente sont comprises entre 2006 et 2010, \n",
        "  * que les 12 mois sont représentés avec une gaussienne avec des ventes plus importantes sur l'été"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aneHV5e9JO4",
        "colab_type": "text"
      },
      "source": [
        "### Les variables catégorielles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUCr05fP9JO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cat = df.select_dtypes(include = ['category'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Gci5oNl6K5S",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(round(len(df_cat.columns) / 3), 3, figsize=(12, 30))\n",
        "\n",
        "for i, ax in enumerate(fig.axes):\n",
        "    if i < len(df_cat.columns):\n",
        "        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)\n",
        "        sns.countplot(x=df_cat.columns[i], alpha=0.7, data=df_cat, ax=ax)\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJO-5lf29JPB",
        "colab_type": "text"
      },
      "source": [
        "Pour un certain nombre de variables catégorielles, une modalité représente la très grande majorité de l'information. Par conséquent, les variables n'ont pas à être prises en compte par la suite dans le modèle. On pourra ne pas considérer les variables suivantes MSZoning, Street, Alley, LandContour, Utilities, LandSlope, Condition1, Condition2, BldgType, RoofMatl, BsmtCond, Heating, BsmtFinType2, CentralAir, Functional, GarageQual, GarageCond, PoolQC,MiscFeature.\n",
        "On peut observer aussi que la qualité de la finition de la maison s'apparente à une gaussienne."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HIj4cpdc6K7R"
      },
      "source": [
        "### Conclusion sur l'analyse univariée\n",
        "\n",
        "On a pu voir que :\n",
        "* notre cible de prix de vente suit une loi LogNormal\n",
        "* un certain nombre de variables numériques ont aussi un comportement assez similaire à notre target en termes de distribution\n",
        "* une élimination naturelle des variables catégorielles n'apportant pas d'informations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pno1sXsB6K7S"
      },
      "source": [
        "## Analyse bivariée\n",
        "\n",
        "L'analyse bivariée va consister à regarder l'influence de différentes variables sur la variable cible.\n",
        "\n",
        "### Les variables quantitatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8lecHIX9JPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = df.corr()\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.heatmap(corr, vmax=.8, square=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLkGpnps9JPL",
        "colab_type": "text"
      },
      "source": [
        "La matrice de corrélation entre les variables quantitatives avec de nombreuses variables permet néanmoins d'extraire des informations intéressantes :\n",
        "* les variables qui sont très fortement corrélées entre elles : on pourra citer YearBuilt et GarageYrBlt, GarageCars et GarageArea et TotalBsmtSF et 1FstFlrSF. Une des deux variables pourra être ignorée dans le cas de la prédiction car elles transmettent une information identique.\n",
        "* un focus spécifique sur la variable à prédire : on peut observer qu'elle est fortement liée positivement à GrLivArea, TotalBsmtSF, GarageCars pour les plus significatives. Elle a l'air corrélée négativement avec KitchenAbvGr et EnclosedPorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DZOyubi9JPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfSalePrice = corr[np.abs(corr['SalePrice'])>0.5]['SalePrice']\n",
        "dfSalePrice = dfSalePrice.drop('SalePrice')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5DAYWxD9JPP",
        "colab_type": "code",
        "outputId": "502bfd15-30ec-4b95-e8ff-187b0f1cb3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "impSalePrice = dfSalePrice.plot(kind=\"bar\")\n",
        "impSalePrice.set_title(\"Importance des variables quantitatives majeures\")\n",
        "impSalePrice.set_ylabel(\"Corrélation en absolu\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(66.45562500000005, 0.5, 'Corrélation en absolu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xIYPnUX9JPS",
        "colab_type": "text"
      },
      "source": [
        "On regarde à travers un scatterplot pour visualiser la relation entre les variables numériques les plus significatives (en gardant uniquement une variable si problème de colinéarité) avec la variable cible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ihj89SB9JPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set()\n",
        "cols = ['SalePrice', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
        "sns.pairplot(df[cols], height = 2.5)\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGp7oDr_9JPW",
        "colab_type": "text"
      },
      "source": [
        "Le prix de vente semble en tendance évoluer positivement fonction du nombre de places de parkings et de salle de bains (même s'il existe une certaine disparité). Faisons un focus sur des liens entre certaines variables avec la variable cible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63v7NBlv9JPX",
        "colab_type": "code",
        "outputId": "cd8c12dd-de5c-4973-d877-c94a854613cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fig,(ax1,ax2) = plt.subplots(ncols=2)\n",
        "fig.set_size_inches(14,10)\n",
        "sns.regplot(x=\"GrLivArea\",y=\"SalePrice\",data=df, ax=ax1)\n",
        "sns.regplot(x=\"TotalBsmtSF\",y=\"SalePrice\",data=df,ax=ax2)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc7bd441438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmeunWUg9JPa",
        "colab_type": "text"
      },
      "source": [
        "Le prix de vente évolue positivement fonction de la surface totale habitable et de l'emprise au sol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTujSGfd9JPb",
        "colab_type": "code",
        "outputId": "71f8a6a8-3602-40a5-cd6d-9803af73bf63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sns.scatterplot(x=\"YearBuilt\",y=\"SalePrice\",data=df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc7bd441438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmNVUtNL9JPf",
        "colab_type": "text"
      },
      "source": [
        "Le prix de vente semble augmenter en fonction de l'année de construction. Peut-être à prendre avec précaution car nous ne savons pas si les prix de vente sont en prix constant. Dans le cas contraire, cela reflète l'inflation de 1880 à 2010."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cu3Oky_o6K7T"
      },
      "source": [
        "### Les variables catégorielles\n",
        "\n",
        "En croisant les variables catégorielles, il est possible de trouver des relations logiques avec notre cible. Pour certaines analyses, il est nécessaire d'avoir une vision métier supplémentaire par exemple pour la logique géographique au niveau des districts (neighborhood) qui peut faire sens pour une personne connaissant le marché immobilier ou qui nécessiterait d'introduire du featuring engeenering avec le niveau de vie moyen par district."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTLl_9t49JPh",
        "colab_type": "code",
        "outputId": "598e5ea2-343a-4a5e-abaf-d3c68b9f1661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sns.catplot(x=\"SalePrice\", y=\"Neighborhood\", kind=\"box\",data=df)\n",
        "plt.title(\"Distribution Prix / Neighborhood\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1, 'Distribution Prix / Neighborhood')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XXXZWUJU6K7T",
        "outputId": "deee8891-c5d0-4c05-c668-931298a4c7ad",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sns.catplot(x=\"OverallQual\", y=\"SalePrice\", kind=\"box\", data=df)\n",
        "plt.title(\"Distribution Prix / OverallQual\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1, 'Distribution Prix / OverallQual')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b59FrHkx6K7X"
      },
      "source": [
        "On observe de manière naturelle que le prix de vente dépend de l'évaluation de la qualité des matériaux et de la finition de la maison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JUbcU87E6K7Y",
        "outputId": "2e63208b-0086-4bdc-edd6-63b8a9c088f4",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sns.catplot(x=\"FireplaceQu\", y=\"SalePrice\", kind=\"box\", order=[\"No Fireplace\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"], data=df)\n",
        "plt.title(\"Distribution Prix / FireplaceQu\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1, 'Distribution Prix / FireplaceQu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EskJSjoL6K7g"
      },
      "source": [
        "Les variables avec une échelle de valeur comme FirePlaceQu (KitchenQual, HeatingQC, BsmtExposure,BsmtCond, BsmtQual, ...) ont un prix qui en tendance évolue positivement fonction d'une note élevée fonction du critère étudiée ce qui apparaît logique avec néanmoins des points atypiques pour certaines modalités. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__Q8PMnl6K8o"
      },
      "source": [
        "### Conclusion sur l'analyse bivariée\n",
        "\n",
        "La target est sensible : \n",
        "* à des variables numériques les plus discriminantes comme la surface, le nombre de places de garage/salle de bain...\n",
        "* à des variables catégorielles comme des échelles de valeurs allant de mauvais à excellent...\n",
        "* certaines variables catégorielles peuvent faire sens mais nécessite une expertise métier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ptoewgST6K8p"
      },
      "source": [
        "## Analyse multivariée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD6sNI2G9JPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"GlobalQuality\"] =df[\"OverallQual\"].replace({1:\"Mauvais\",2:\"Mauvais\",3:\"Faible\",4:\"Faible\",5:\"Moyen\",6:\"Moyen\",7:\"Bon\",8:\"Bon\",9:\"Excellent\",10:\"Excellent\"}) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DkgC3IOO6K8q",
        "outputId": "d6a913b1-350b-435c-fceb-c23312bbd1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sns.scatterplot(x=\"GrLivArea\", y=\"SalePrice\", hue=\"GlobalQuality\", data=df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc7bd045be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fkaS0XD46K8u"
      },
      "source": [
        "On peut observer que le prix dépend fortement de la surface et de la qualité de la maison. Les maisons les plus chères sont les plus grandes avec une très bonne notation et inversement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TymTuh79JP1",
        "colab_type": "code",
        "outputId": "48d4be9c-caba-41e5-bb29-d667d192e88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sns.scatterplot(x=\"YearBuilt\", y=\"SalePrice\", hue=\"GlobalQuality\", data=df)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc7bd045be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7QIjVN3_6K8z"
      },
      "source": [
        "On avait pu observer que le prix de vente (moyennant le fait qu'on ne sait si on raisonne en prix constant) augmente en tendance fonction de l'année de construction. On observe aussi que l'appréciation de qualité est plus élevée (bon, excellent) si la maison est récente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gt6LuI3r6K86"
      },
      "source": [
        "### Conclusion sur l'analyse multivariée\n",
        "\n",
        "D'autres analyses multivariées auraient pu être réalisées aux vues du nombre de variables dans le jeu de données. Nous avons isolé quelques analyses multivariées permettant de voir des tendances entre certaines variables et la variable cible.\n",
        "\n",
        "L'analyse exploratoire nous a permis :\n",
        "* de voir la distribution de notre variable cible\n",
        "* d'éliminer certaines variables catégorielles ne présentant pas d'information utile dans le cas de sur-représentation d'une modalité majoritaire\n",
        "* d'éliminer les variables numériques qui ont une corrélation très importantes entre elles : elles expriment le même type d'information\n",
        "* les liens à travers les variables catégorielles et numériques significatives par rapport à notre cible à travers des analyses bivariées ou multivariées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G06HTgij6K86"
      },
      "source": [
        "# Preprocessing pour scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qADGFBuU6X0X",
        "colab_type": "text"
      },
      "source": [
        "## Lecture des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kMM1rSW96K87",
        "outputId": "553861fc-916c-47a1-bd26-14ea8d1855ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "df_train = pd.read_csv(\"https://raw.githubusercontent.com/anthonymoisan/DeepLearningPredictHousePrices/master/input/train.csv\")\n",
        "print(\"taille du jeu de donnees train :\", df_train.shape)\n",
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/anthonymoisan/DeepLearningPredictHousePrices/master/input/test.csv\")\n",
        "print(\"taille du jeu de donnees test :\", df_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taille du jeu de donnees train : (1460, 81)\n",
            "taille du jeu de donnees test : (1459, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dba_5GK99JP8",
        "colab_type": "text"
      },
      "source": [
        "L'ensemble de train est l'ensemble d'apprentissage sur lequel on va construire et valider notre modèle. L'ensemble de test a le même nombre de variables explicatives et doit permettre d'inférer le prix de ventes avec le modèle. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BCZ8HXC9JP8",
        "colab_type": "text"
      },
      "source": [
        "## Prise en compte de l'analyse exploratoire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ke0ltzW9JP9",
        "colab_type": "text"
      },
      "source": [
        "Définition des variables catégorielles et des champs NA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5-aMIUJ9JP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DefineCategoricalVariableAndDefineNa(df_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiI1FlpX9JP_",
        "colab_type": "text"
      },
      "source": [
        "L'analyse exploratoire a permis d'identifier des variables numériques et catégorielles à enlever car n'apportant pas d'informations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO5LWqQQ9JP_",
        "colab_type": "code",
        "outputId": "0e1564a2-4022-47d8-f16c-7ad2659ba55f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "listDropNumerical = [\"Id\", \"GarageYrBlt\",  \"GarageCars\", \"1stFlrSF\"] \n",
        "listDropCategorical = [\"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"Utilities\", \"LandSlope\", \"Condition1\", \"Condition2\", \"BldgType\", \"RoofMatl\", \"BsmtCond\", \"Heating\", \"BsmtFinType2\", \"CentralAir\", \"Functional\", \"GarageQual\", \"GarageCond\", \"PoolQC\",\"MiscFeature\"]\n",
        "print(\"Nombre de variables catégoriques à supprimer : \" + str(len(listDropCategorical)))\n",
        "print(\"Nombre de variables numériques à supprimer : \" + str(len(listDropNumerical)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de variables catégoriques à supprimer : 19\n",
            "Nombre de variables numériques à supprimer : 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajfe6Zv39JQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train.drop(listDropNumerical, axis = 1)\n",
        "df_train = df_train.drop(listDropCategorical, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYzvAwpz9JQG",
        "colab_type": "code",
        "outputId": "1d0cdd50-8cac-4efc-cc5b-12b1a7bf33f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Taille du dataset suite à prétraitements : \", df_train.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taille du dataset suite à prétraitements :  (1460, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YAKJ5_w6K89"
      },
      "source": [
        "## Construction des ensembles X et y à partir du dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wriVcsZv6K8-"
      },
      "source": [
        "On construit l'ensemble X, y sur le dataframe résultant :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zmdt31oC6K8-",
        "colab": {}
      },
      "source": [
        "X = df_train.drop([\"SalePrice\"], axis = 1)\n",
        "y = df_train[\"SalePrice\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ft3p3n8M6K9B"
      },
      "source": [
        "## Preprocessing sur les variables catégorielles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDMmcvVs9JQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxGF8xiX9JQQ",
        "colab_type": "text"
      },
      "source": [
        "Scikit-learn ne reconnait pas les objets de type DataFrame directement, notamment les types catégoriels. Il faut donc préparer nos données afin que les méthodes de scikit-learn puissent les interpréter. Scikit learn requiert un encodage numérique des ces variables. Nous allons donc devoir encoder nos variables explicatives catégorielles à l'aide de variables indicatrices et nous utilison pour cela OneHotEncooder et on impute les modalités manquantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "siVLYZ5-6K9D",
        "outputId": "2c91c059-dab8-4c28-93d2-207bf3214264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "categorical_features = X.columns[X.dtypes == \"category\"].tolist()\n",
        "print(categorical_features)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MSSubClass', 'LotShape', 'LotConfig', 'Neighborhood', 'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC', 'Electrical', 'KitchenQual', 'FireplaceQu', 'GarageType', 'GarageFinish', 'PavedDrive', 'Fence', 'SaleType', 'SaleCondition']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCU9iDEg9JQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_6TGT-49JQX",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing sur les variables numériques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89-ADCYo9JQY",
        "colab_type": "text"
      },
      "source": [
        "Certaines méthodes d'apprentissage sont sensibles aux problèmes d'échelle sur les valeurs numériques. En preprocessing, on standardise les variables numériques en retranchant leur moyenne et en divisant par l'écart type via Scikit-learn et la méthode StandardScaler. Dans le cas présent, on mélange des unités différentes donc la standardisation semble appropriée. On a pu aussi voir qu'il y avait des données manquantes sur certaines variables numériques comme LotFrontage que l'on impute par la moyenne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPJQX-Di9JQb",
        "colab_type": "code",
        "outputId": "053319b6-9658-416a-b4b0-2bfd01d46a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "numerical_features = X.columns[X.dtypes == \"int64\"].tolist()+X.columns[X.dtypes == \"float64\"].tolist()\n",
        "print(categorical_features)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MSSubClass', 'LotShape', 'LotConfig', 'Neighborhood', 'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC', 'Electrical', 'KitchenQual', 'FireplaceQu', 'GarageType', 'GarageFinish', 'PavedDrive', 'Fence', 'SaleType', 'SaleCondition']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8kaU0Ia9JQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IdHq07c9JQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NYugeEYv6K9N"
      },
      "source": [
        "## Train, Val\n",
        "\n",
        "Nous allons prendre sur le training 70% pour le train et 30% pour la validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L2GJmOIg6K9N",
        "outputId": "43597ea6-9fcb-4d07-9d31-3425c22279fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=777)\n",
        "print(f\"Shape du X_train : {X_train.shape}\")\n",
        "print(f\"Shape du y_train : {y_train.shape}\")\n",
        "print(f\"Shape du X_test : {X_test.shape}\")\n",
        "print(f\"Shape du y_test : {y_test.shape}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape du X_train : (1022, 57)\n",
            "Shape du y_train : (1022,)\n",
            "Shape du X_test : (438, 57)\n",
            "Shape du y_test : (438,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHEDDGuM9JQn",
        "colab_type": "text"
      },
      "source": [
        "Nous standardisons aussi notre cible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ckENc659JQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Yscaler = StandardScaler()\n",
        "y_train = Yscaler.fit_transform(y_train[:, None])[:, 0]\n",
        "y_test = Yscaler.transform(y_test[:, None])[:, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5A3tksWS6K9W"
      },
      "source": [
        "# Des modèles basées sur la régression linéaire \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgvhC2iC5_Yo",
        "colab_type": "text"
      },
      "source": [
        "## Un modèle simple : la régression linéaire\n",
        "\n",
        "Un premier modèle qui nous servira de *baseline*.\n",
        "\n",
        "Nous allons aussi introduire l'imputation sur les données sur les données *train*, que nous appliquerons **ENSUITE** sur les données *test*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8WRecKi6C-T",
        "colab_type": "text"
      },
      "source": [
        "### Modèle de regression sur Train/Test\n",
        "$$y =\\sum_{i=1}^{n} a_i \\times x_i + b$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAAGj5Le9JQr",
        "colab_type": "code",
        "outputId": "2af1eb00-12cf-44ad-8493-3897fa791f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "clfRegLinear = Pipeline(steps=[('preprocessor', preprocessor), ('LinearRegression', LinearRegression())])\n",
        "clfRegLinear.fit(X_train,y_train)\n",
        "y_trainPredict = clfRegLinear.predict(X_train)\n",
        "y_testPredict = clfRegLinear.predict(X_test)\n",
        "print(\"model score le test : %.3f\" % clfRegLinear.score(X_test, y_test))\n",
        "print(\"model score sur le train :  %.3f\" % clfRegLinear.score(X_train, y_train))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score le test : 0.853\n",
            "model score sur le train :  0.891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrQ-AxhZ9JQu",
        "colab_type": "text"
      },
      "source": [
        "On observe à priori un modèle avec un coefficient de détermination correct et on a une bonne généralisation sur l'ensemble de validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UQiCkk_j6K9Z"
      },
      "source": [
        "### Coefficients de la régression linéaire\n",
        "\n",
        "Un des avantages de la régression linéaire est que nous pouvons obtenir les coefficients associés à chacune des variables. Nous pouvons voir les coefficients qui ont un impact sur le nombre de vélos loués.\n",
        "\n",
        "Regardons ces coefficients :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYY9wwKf9JQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ohe = (clfRegLinear.named_steps['preprocessor']\n",
        "         .named_transformers_['cat']\n",
        "         .named_steps['onehot'])\n",
        "feature_names = ohe.get_feature_names(input_features=categorical_features)\n",
        "feature_names = np.r_[numerical_features, feature_names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1aMQzKWG6K9Z",
        "outputId": "1e4b448a-5c4f-4a54-f20c-bb5ae0ae55d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "coefficients = pd.Series(clfRegLinear.named_steps[\"LinearRegression\"].coef_.flatten(), index=feature_names).sort_values(ascending=False)\n",
        "coefficients"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OverallQual_10          0.940247\n",
              "OverallQual_9           0.742062\n",
              "Exterior1st_Stone       0.582463\n",
              "Neighborhood_NoRidge    0.574580\n",
              "SaleType_New            0.570265\n",
              "                          ...   \n",
              "Exterior2nd_CmentBd    -0.490410\n",
              "HouseStyle_2.5Fin      -0.510151\n",
              "OverallQual_1          -0.528082\n",
              "Exterior1st_ImStucc    -0.640948\n",
              "Foundation_Wood        -0.752301\n",
              "Length: 234, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0-FlFKAr6K9b",
        "outputId": "1280a6ec-ba9f-4b7b-ddbb-e2cad6a8e184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"ordonnee à l'origine : \" + str(clfRegLinear.named_steps[\"LinearRegression\"].intercept_))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ordonnee à l'origine : -0.19533366583177567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4fHth74q6K9d",
        "colab": {}
      },
      "source": [
        "coefficients[np.abs(coefficients)>0.4].plot(kind=\"bar\")\n",
        "plt.title(\"Regression lineaire coefficient\")\n",
        "plt.ylabel(\"Coefficient value\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MPpyUAol6K9i"
      },
      "source": [
        "On observe une cohérence par rapport notamment aux échelles de notation (OverallQual) qui joue de manière positive ou négative sur le prix. On observe aussi qu'être dans les districts NoRidge, StoneBr, NridgHt ou Edwards à un impact positif, des fondations en pierre ou un extérieur en pierre joue de manière positive dans le prix contrairement à des fondations en bois"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MHBss3WB6K9i"
      },
      "source": [
        "### Evaluation de la régression avec différentes métriques\n",
        "\n",
        "Nous allons regarder quelques métriques associées aux problématiques de régression :\n",
        "* L'erreur maximum entre la prédiction et la réalité\n",
        "* La moyenne des erreurs absolus entre la prédiction et la réalité\n",
        "* La moyenne des erreurs au carré entre la prédiction et la réalité (MSE)\n",
        "* Le score R2 qui est le coefficient de détermination en comparant MSE et la variance. Fonction renvoyée par la méthode score de Scikit Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VchNswW36K9i",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def regression_metrics(y, y_pred):\n",
        "    return pd.DataFrame(\n",
        "        {\n",
        "            \"max_error\": metrics.max_error(y_true=y, y_pred=y_pred),\n",
        "            \"mean_absolute_error\": metrics.mean_absolute_error(y_true=y, y_pred=y_pred),\n",
        "            \"mean_squared_error\": metrics.mean_squared_error(y_true=y, y_pred=y_pred),\n",
        "            \"r2_score\": metrics.r2_score(y_true=y, y_pred=y_pred)\n",
        "        },\n",
        "        index=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XKCpMDNQ6K9p",
        "outputId": "adc2f1d4-ac32-4830-ab3b-04d24059f177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(\"Regression metrics for train data\")\n",
        "print(regression_metrics(Yscaler.inverse_transform(y_train), Yscaler.inverse_transform(y_trainPredict)))\n",
        "print(\"Regression metrics for test data\")\n",
        "print(regression_metrics(Yscaler.inverse_transform(y_test), Yscaler.inverse_transform(y_testPredict)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regression metrics for train data\n",
            "       max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  268648.274025         16821.411538        7.489736e+08  0.890839\n",
            "Regression metrics for test data\n",
            "       max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  170230.331078          19058.74088        7.289663e+08  0.852876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U1QOHL-q6K9s"
      },
      "source": [
        "On retrouve la bonne généralisation quelque soit la métrique utilisée. Si on regarde en moyenne l'erreur absolu, on se trompe de l'ordre de 20000. Néanmoins, on peut aussi constater qu'avec le modèle de régression linéaire généralisée, on peut se tromper fortement sur l'estimation du prix > 170000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7VJttqe9JRD",
        "colab_type": "text"
      },
      "source": [
        "## Un modèle de régression linéaire Lasso\n",
        "\n",
        "### Modèle de regression Lasso sur Train/Test\n",
        "Ce modèle intègre en plus un terme de régularisation L1 sur la régression linéaire et force par conséquent un certain nombre de coefficients à être à 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAiZ3ncx9JRD",
        "colab_type": "code",
        "outputId": "03c6a04e-bb1c-4aa4-b052-8d17938a7b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        }
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "bestScore = 0\n",
        "bestAlpha = 0\n",
        "for alpha in [0.00001, 0.0001, 0.001,0.01, 0.1, 1, 10, 100, 1000 ]:\n",
        "    print(\"Lasso avec regul : \" + str(alpha))\n",
        "    clfLasso = Pipeline(steps=[('preprocessor', preprocessor), ('LassoRegression', Lasso(alpha=alpha))])\n",
        "    clfLasso.fit(X_train,y_train)\n",
        "    #y_trainPredict = clfLasso.predict(X_train)\n",
        "    #y_testPredict = clfLasso.predict(X_test)\n",
        "    scoreTest = clfLasso.score(X_test, y_test)\n",
        "    print(\"model score le test : %.3f\" % scoreTest)\n",
        "    print(\"model score sur le train :  %.3f\" % clfLasso.score(X_train, y_train))\n",
        "    if( scoreTest > bestScore):\n",
        "        bestScore = scoreTest\n",
        "        bestAlpha = alpha\n",
        "print(\"\\n\\n\\n-----------------------------------------------\\nLasso best score : %.3f\" % bestScore)\n",
        "print(\"Lasso best regularization : \" + str(bestAlpha))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lasso avec regul : 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:459: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.973060312336798, tolerance: 0.10220000000000003\n",
            "  max_iter, tol, rng, random, positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model score le test : 0.855\n",
            "model score sur le train :  0.891\n",
            "Lasso avec regul : 0.0001\n",
            "model score le test : 0.864\n",
            "model score sur le train :  0.890\n",
            "Lasso avec regul : 0.001\n",
            "model score le test : 0.887\n",
            "model score sur le train :  0.882\n",
            "Lasso avec regul : 0.01\n",
            "model score le test : 0.871\n",
            "model score sur le train :  0.826\n",
            "Lasso avec regul : 0.1\n",
            "model score le test : 0.775\n",
            "model score sur le train :  0.707\n",
            "Lasso avec regul : 1\n",
            "model score le test : -0.017\n",
            "model score sur le train :  0.000\n",
            "Lasso avec regul : 10\n",
            "model score le test : -0.017\n",
            "model score sur le train :  0.000\n",
            "Lasso avec regul : 100\n",
            "model score le test : -0.017\n",
            "model score sur le train :  0.000\n",
            "Lasso avec regul : 1000\n",
            "model score le test : -0.017\n",
            "model score sur le train :  0.000\n",
            "\n",
            "\n",
            "\n",
            "-----------------------------------------------\n",
            "Lasso best score : 0.887\n",
            "Lasso best regularization : 0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvYzBEAQ9JRG",
        "colab_type": "text"
      },
      "source": [
        "Une régularisation importante conduit à des résultats surprenants qui peuvent s'expliquer peut-être par la standardisation de la variable y (sans la standardisation de celle-ci, les coefficients étaient beaucoup plus grands et le paramètre de régularisation optimale était de 100)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaTYlGUK9JRH",
        "colab_type": "text"
      },
      "source": [
        "### Coefficients de la régression linéaire Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aThuWpvl9JRH",
        "colab_type": "code",
        "outputId": "09d7533a-219c-4bc8-bfe0-4a60abdfcabf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "clfLasso = Pipeline(steps=[('preprocessor', preprocessor), ('LassoRegression', Lasso(alpha=0.001))])\n",
        "clfLasso.fit(X_train,y_train)\n",
        "y_trainPredictLasso = clfLasso.predict(X_train)\n",
        "y_testPredictLasso = clfLasso.predict(X_test)\n",
        "print(\"model score le test : %.3f\" % clfLasso.score(X_test, y_test))\n",
        "print(\"model score sur le train :  %.3f\" % clfLasso.score(X_train, y_train))\n",
        "\n",
        "coefficientsLasso = pd.Series(clfLasso.named_steps[\"LassoRegression\"].coef_.flatten(), index=feature_names).sort_values(ascending=False)\n",
        "print(\"\\nCoefficients totaux : \"+ str(len(coefficientsLasso)))\n",
        "print(\"Dont coefficients nuls : \"+ str(sum(coefficientsLasso == 0)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score le test : 0.887\n",
            "model score sur le train :  0.882\n",
            "\n",
            "Coefficients totaux : 234\n",
            "Dont coefficients nuls : 111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5E8wYb79JRN",
        "colab_type": "code",
        "outputId": "7955eaa1-8dd7-4e72-98b6-30f7761668c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "coefficientsLasso"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OverallQual_10          0.900954\n",
              "OverallQual_9           0.781774\n",
              "Neighborhood_NoRidge    0.573501\n",
              "Neighborhood_StoneBr    0.479460\n",
              "Neighborhood_NridgHt    0.364574\n",
              "                          ...   \n",
              "MSSubClass_120         -0.146227\n",
              "BsmtQual_No Basement   -0.151211\n",
              "Neighborhood_Edwards   -0.250958\n",
              "MSSubClass_160         -0.257290\n",
              "LotShape_IR3           -0.350952\n",
              "Length: 234, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7SvbhHi9JRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coefficients[np.abs(coefficients)>0.4].plot(kind=\"bar\")\n",
        "plt.title(\"Regression lineaire Lasso coefficient\")\n",
        "plt.ylabel(\"Coefficient value\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDM6682K9JRT",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation de la régression Lasso avec différentes métriques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em4vdMzw9JRU",
        "colab_type": "code",
        "outputId": "d35eb482-0966-4d7f-d99e-2cc85da53204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(\"Regression metrics for train data\")\n",
        "print(regression_metrics(Yscaler.inverse_transform(y_train), Yscaler.inverse_transform(y_trainPredictLasso)))\n",
        "print(\"Regression metrics for test data\")\n",
        "print(regression_metrics(Yscaler.inverse_transform(y_test), Yscaler.inverse_transform(y_testPredictLasso)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regression metrics for train data\n",
            "       max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  309318.171409         16624.623402        8.089878e+08  0.882092\n",
            "Regression metrics for test data\n",
            "       max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  150555.331076         16747.844669        5.614283e+08  0.886689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtty221U9JRW",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion sur les régressions linéaires\n",
        "\n",
        "* Les régressions linéaires généralisées et Lasso réalisées mettent en avant les mêmes variables explicatives et ont des scores assez similaires avec des coefficients de détermination correctes.\n",
        "* Suivant la métrique à considérer, un modèle pourra être mis en avant.\n",
        "* Néanmoins il apparait assez surprenant de ne pas retrouver dans les variables prépondérantes les variables numériques comme GrLivArea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8tzW1PL9JRX",
        "colab_type": "code",
        "outputId": "c3120902-32c3-4181-8551-f413ebf4412c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "(\"Reg Linéaire : \", coefficients[\"GrLivArea\"], \"Reg Lasso : \", coefficientsLasso[\"GrLivArea\"])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Reg Linéaire : ', 0.16389762960965606, 'Reg Lasso : ', 0.1889702781769011)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11aKbJki9JRZ",
        "colab_type": "text"
      },
      "source": [
        "En termes de perspectives : \n",
        "* une validation croisée pourrait être mise en oeuvre pour définir plus précisément le modèle en étant robuste à la détermination de l'ensemble d'apprentissage et de validation\n",
        "* du featuring engineering pourrait être réalisé pour agréger éventuellement les données sur les surfaces afin qu'elle ressorte plus distinctement dans la régression comme un facteur explicatif du prix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-OgNkA3YhMQ",
        "colab_type": "text"
      },
      "source": [
        "#Réseau de neurones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPXCwypU5DBB",
        "colab_type": "text"
      },
      "source": [
        "## Librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zSVM5o0YmsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "92babd4e-f774-44ad-801f-f92dacf02d22"
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/docs\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-wzsad7sm\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-wzsad7sm\n",
            "Requirement already satisfied (use --upgrade to upgrade): tensorflow-docs==0.0.0 from git+https://github.com/tensorflow/docs in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs==0.0.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs==0.0.0) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs==0.0.0) (1.12.0)\n",
            "Requirement already satisfied: pathlib2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs==0.0.0) (2.3.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs==0.0.0) (3.13)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0-cp36-none-any.whl size=80660 sha256=771257d40ff97f1bda8b012af275372b5deeb484ad0c9a82661aa73b81328291\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9s86mtzn/wheels/eb/1b/35/fce87697be00d2fc63e0b4b395b0d9c7e391a10e98d9a0d97f\n",
            "Successfully built tensorflow-docs\n",
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfb0kkhKxE9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "90e5ac3d-80e9-4fee-a53b-18c6cfc047ec"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>45</td>\n",
              "      <td>59.0</td>\n",
              "      <td>7227</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Corner</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>1.5Unf</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1954</td>\n",
              "      <td>1954</td>\n",
              "      <td>Gable</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>832</td>\n",
              "      <td>832</td>\n",
              "      <td>Gd</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>832</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fireplace</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>Unf</td>\n",
              "      <td>528</td>\n",
              "      <td>Paved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1114</th>\n",
              "      <td>20</td>\n",
              "      <td>90.0</td>\n",
              "      <td>5400</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Inside</td>\n",
              "      <td>OldTown</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1954</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Rec</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>418</td>\n",
              "      <td>833</td>\n",
              "      <td>Ex</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fireplace</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>Unf</td>\n",
              "      <td>326</td>\n",
              "      <td>Paved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>20</td>\n",
              "      <td>95.0</td>\n",
              "      <td>13651</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Inside</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>1Story</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1973</td>\n",
              "      <td>1973</td>\n",
              "      <td>Gable</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>1115.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>1880</td>\n",
              "      <td>0</td>\n",
              "      <td>343</td>\n",
              "      <td>2223</td>\n",
              "      <td>Ex</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2223</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>Fin</td>\n",
              "      <td>516</td>\n",
              "      <td>Paved</td>\n",
              "      <td>300</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Inside</td>\n",
              "      <td>NWAmes</td>\n",
              "      <td>1Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1969</td>\n",
              "      <td>1969</td>\n",
              "      <td>Hip</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>168.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1164</td>\n",
              "      <td>1164</td>\n",
              "      <td>TA</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1164</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fireplace</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>Unf</td>\n",
              "      <td>528</td>\n",
              "      <td>Paved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2006</td>\n",
              "      <td>COD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>20</td>\n",
              "      <td>76.0</td>\n",
              "      <td>9158</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Somerst</td>\n",
              "      <td>1Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>2007</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CemntBd</td>\n",
              "      <td>CmentBd</td>\n",
              "      <td>Stone</td>\n",
              "      <td>140.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Av</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1496</td>\n",
              "      <td>1496</td>\n",
              "      <td>Ex</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1496</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fireplace</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>Fin</td>\n",
              "      <td>474</td>\n",
              "      <td>Paved</td>\n",
              "      <td>168</td>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2007</td>\n",
              "      <td>New</td>\n",
              "      <td>Partial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>639</th>\n",
              "      <td>120</td>\n",
              "      <td>53.0</td>\n",
              "      <td>3982</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Blmngtn</td>\n",
              "      <td>1Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2006</td>\n",
              "      <td>2006</td>\n",
              "      <td>Hip</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>1154</td>\n",
              "      <td>0</td>\n",
              "      <td>366</td>\n",
              "      <td>1520</td>\n",
              "      <td>Ex</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1567</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Ex</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>Fin</td>\n",
              "      <td>648</td>\n",
              "      <td>Paved</td>\n",
              "      <td>312</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2006</td>\n",
              "      <td>New</td>\n",
              "      <td>Partial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>20</td>\n",
              "      <td>69.0</td>\n",
              "      <td>7599</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Mitchel</td>\n",
              "      <td>1Story</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1982</td>\n",
              "      <td>2006</td>\n",
              "      <td>Gable</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>565</td>\n",
              "      <td>0</td>\n",
              "      <td>280</td>\n",
              "      <td>845</td>\n",
              "      <td>TA</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>845</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fireplace</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>Unf</td>\n",
              "      <td>360</td>\n",
              "      <td>Paved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>20</td>\n",
              "      <td>313.0</td>\n",
              "      <td>27650</td>\n",
              "      <td>IR2</td>\n",
              "      <td>Inside</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>1Story</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1960</td>\n",
              "      <td>2007</td>\n",
              "      <td>Flat</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Gd</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>425</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>585</td>\n",
              "      <td>Ex</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2069</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>505</td>\n",
              "      <td>Paved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>20</td>\n",
              "      <td>48.0</td>\n",
              "      <td>12137</td>\n",
              "      <td>IR2</td>\n",
              "      <td>CulDSac</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>1Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1998</td>\n",
              "      <td>1998</td>\n",
              "      <td>Gable</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>442.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1649</td>\n",
              "      <td>1649</td>\n",
              "      <td>Ex</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1661</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fireplace</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>598</td>\n",
              "      <td>Paved</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>20</td>\n",
              "      <td>94.0</td>\n",
              "      <td>10402</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Corner</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>1Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>Gable</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1226</td>\n",
              "      <td>1226</td>\n",
              "      <td>Ex</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1226</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fireplace</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>740</td>\n",
              "      <td>Paved</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Fence</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1022 rows × 57 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     MSSubClass  LotFrontage  LotArea  ... YrSold SaleType SaleCondition\n",
              "617          45         59.0     7227  ...   2008       WD        Normal\n",
              "1114         20         90.0     5400  ...   2006       WD        Normal\n",
              "70           20         95.0    13651  ...   2007       WD        Normal\n",
              "701          20         80.0     9600  ...   2006      COD        Normal\n",
              "793          20         76.0     9158  ...   2007      New       Partial\n",
              "...         ...          ...      ...  ...    ...      ...           ...\n",
              "639         120         53.0     3982  ...   2006      New       Partial\n",
              "71           20         69.0     7599  ...   2007       WD        Normal\n",
              "934          20        313.0    27650  ...   2008       WD        Normal\n",
              "815          20         48.0    12137  ...   2010       WD        Normal\n",
              "103          20         94.0    10402  ...   2010       WD        Normal\n",
              "\n",
              "[1022 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6Ph60sZ5KDx",
        "colab_type": "text"
      },
      "source": [
        "## Préprocessing sur les données\n",
        "\n",
        "On réutilise les transformations précédentes sur les variables numériques et catégorielles :\n",
        "* pour les variables catégorielles : OneHotEncoding et imputation des valeurs manquantes\n",
        "* pour les variables numériques : recalibration entre 0 et 1 et imputation des valeurs manquantes par la moyenne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvX0XAOT5-E1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d9ae9cd0-9619-41f3-869a-d1ffd0d45f43"
      },
      "source": [
        "print(\"shape de X_train : \" + str(X_train.shape))\n",
        "print(\"shape de X_test : \" + str(X_test.shape))\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "print(\"shape de X_train_transformed : \"+ str(X_train_transformed.shape))\n",
        "print(\"shape de X_test_transformed : \"+ str(X_test_transformed.shape))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape de X_train : (1022, 57)\n",
            "shape de X_test : (438, 57)\n",
            "shape de X_train_transformed : (1022, 234)\n",
            "shape de X_test_transformed : (438, 234)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdW1i-je7tZ9",
        "colab_type": "text"
      },
      "source": [
        "La target à savoir le prix de vente est aussi entre 0 et 1 car nous avions déjà appliqué un processus de standardisation et cela peut avoir de l'importance car non seulement, cela facilite la phase d'apprentissage mais peut aussi donner des résultats meilleurs dans le modèle de régression avec un réseau de neurones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5DHNYsRAKzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimInput = X_train_transformed.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcJGCFTn9CmM",
        "colab_type": "text"
      },
      "source": [
        "## Architectures du réseau de neurones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jBZvPiXmJvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(unitsLayer1 =64, unitsLayer2 = 64, dropOut=False):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Dense(unitsLayer1, activation='relu', input_shape=[dimInput]))\n",
        "  if(dropOut):\n",
        "    model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(unitsLayer2, activation='relu'))\n",
        "  if(dropOut):\n",
        "    model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(1, activation=\"linear\"))\n",
        "  \n",
        "  \n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eoyq8VtvqhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_4Layers(unitsLayer1 = 32, unitsLayer2 = 16, unitsLayer3 = 8, unitsLayer4 = 4, dropOut=False):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Dense(unitsLayer1, activation='relu', input_shape=[dimInput]))\n",
        "  if(dropOut):\n",
        "    model.add(layers.Dropout(0.05))\n",
        "  model.add(layers.Dense(unitsLayer2, activation='relu'))\n",
        "  if(dropOut):\n",
        "    model.add(layers.Dropout(0.05))\n",
        "  model.add(layers.Dense(unitsLayer3, activation='relu'))\n",
        "  if(dropOut):\n",
        "    model.add(layers.Dropout(0.05))\n",
        "  model.add(layers.Dense(unitsLayer4, activation='relu'))\n",
        "  if(dropOut):\n",
        "    model.add(layers.Dropout(0.05))\n",
        "  model.add(layers.Dense(1, activation=\"linear\"))  \n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdDUsYl_EA5o",
        "colab_type": "text"
      },
      "source": [
        "### Modèle avec 2 couches cachées et 64 neurones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01OemCDmaeMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_64_64_1 = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG0gbBN7amaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "3f052035-b34d-48e4-f007-e6e1f49d5d84"
      },
      "source": [
        "model_64_64_1.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                15040     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 19,265\n",
            "Trainable params: 19,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcyCoWXnC-yN",
        "colab_type": "text"
      },
      "source": [
        "La fonction summary permet d'inspecter le réseau de neurones et de voir le nombre de paramètres associés à chaque couche. Par exemple 15040 correspond au 234 features + 1 pour le biais multipliés par 64 (le nombre de neurones de la première couche cachée)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8nfJmsfXta8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "b3ee0f94-b9cd-49af-a536-224428d9e053"
      },
      "source": [
        "model_64_64_1_DropOut = build_model(dropOut=True)\n",
        "model_64_64_1_DropOut.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 64)                15040     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 19,265\n",
            "Trainable params: 19,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khvC_SiEYy9E",
        "colab_type": "text"
      },
      "source": [
        "__**Initialement**__ : on s'est rendu compte après la phase d'entrainement d'un overfitting important. On initialise la même architecture mais en utilisant la fonctionnalité dropOut pour désactiver 30% des neurones pendant la phase d'entrainement de manière aléatoire dans les couches cachées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgr296kUEzVX",
        "colab_type": "text"
      },
      "source": [
        "### Modèle avec 2 couches cachées et 32 neurones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwGZhIJlkk2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "40a50b6d-d963-49ae-db3c-c0b385d4baac"
      },
      "source": [
        "model_32_32_1 = build_model(unitsLayer1=32, unitsLayer2 =32, dropOut=False)\n",
        "model_32_32_1.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 32)                7520      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 8,609\n",
            "Trainable params: 8,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1jWwWv7k7vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "d3a94711-8f6d-479c-f332-a3dc657bd62a"
      },
      "source": [
        "model_32_32_1_DropOut = build_model(unitsLayer1=32, unitsLayer2 =32,dropOut=True)\n",
        "model_32_32_1_DropOut.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 32)                7520      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 8,609\n",
            "Trainable params: 8,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au0k_J1U3Ijq",
        "colab_type": "text"
      },
      "source": [
        "### Modèle avec 4 couches cachées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3rcWDRXwMaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "3ca032e6-4f5d-4af7-974b-14ee6d3847b9"
      },
      "source": [
        "model_32_16_8_4_1 = build_model_4Layers()\n",
        "model_32_16_8_4_1.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 32)                7520      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 8,225\n",
            "Trainable params: 8,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yM96Xad3gKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "8aae5ef8-45d1-4eb8-b55c-070cd8b122f2"
      },
      "source": [
        "model_32_16_8_4_1_DropOut = build_model_4Layers(dropOut=True)\n",
        "model_32_16_8_4_1_DropOut.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_17 (Dense)             (None, 32)                7520      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 8,225\n",
            "Trainable params: 8,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c07xP1DIE7AC",
        "colab_type": "text"
      },
      "source": [
        "## Entrainement et évaluation des réseaux de neurones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bidd66BPl_Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TrainingNetwork(model, networkName, callback=False):\n",
        "  # train the model\n",
        "  import time\n",
        "  start_time = time.time()\n",
        "  if(callback):\n",
        "    print(\"Training model network \" + networkName + \" with Callback\")\n",
        "  else :\n",
        "    print(\"Training model network \" + networkName)\n",
        "  \n",
        "  if(callback):\n",
        "    # The patience parameter is the amount of epochs to check for improvement\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    model.fit(X_train_transformed.toarray(), y_train, validation_data=(X_test_transformed.toarray(), y_test), epochs=200, batch_size=32, callbacks=[early_stop])\n",
        "  else:\n",
        "    model.fit(X_train_transformed.toarray(), y_train, validation_data=(X_test_transformed.toarray(), y_test), epochs=200, batch_size=32)  \n",
        "  print(\"Temps d'entrainement %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMFqhz4mn6F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PredictionAndEvaluationNetwork(model, networkName, callback=False):\n",
        "  # make predictions on the testing data\n",
        "  if(callback):\n",
        "    print(\"Predicting house prices model network \"+ networkName + \" with Callback\")\n",
        "  else :\n",
        "    print(\"Predicting house prices model network \"+ networkName)\n",
        "  y_testPredict = model.predict(X_test_transformed.toarray())\n",
        "  y_trainPredict = model.predict(X_train_transformed.toarray())\n",
        "  print(\"Regression metrics for train data\")\n",
        "  print(regression_metrics(Yscaler.inverse_transform(y_train), Yscaler.inverse_transform(y_trainPredict)))\n",
        "  print(\"Regression metrics for test data\")\n",
        "  print(regression_metrics(Yscaler.inverse_transform(y_test), Yscaler.inverse_transform(y_testPredict)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyqQO0fkFEaG",
        "colab_type": "text"
      },
      "source": [
        "### Modèle avec 2 couches cachées et 64 neurones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJdcMQZgnQgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd586fb9-7040-4226-ad04-2e0e81c9716c"
      },
      "source": [
        "TrainingNetwork(model_64_64_1, str(64) +\" * \" + str(64) + \" * 1\")\n",
        "PredictionAndEvaluationNetwork(model_64_64_1, str(64) +\" * \" + str(64) + \" * 1\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model network 64 * 64 * 1\n",
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 964us/sample - loss: 0.3576 - mae: 0.3616 - mse: 0.3576 - val_loss: 0.1343 - val_mae: 0.2704 - val_mse: 0.1343\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.2043 - mae: 0.2595 - mse: 0.2043 - val_loss: 0.0967 - val_mae: 0.2163 - val_mse: 0.0967\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.1527 - mae: 0.2186 - mse: 0.1527 - val_loss: 0.0998 - val_mae: 0.2097 - val_mse: 0.0998\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.1158 - mae: 0.2008 - mse: 0.1158 - val_loss: 0.0990 - val_mae: 0.2272 - val_mse: 0.0990\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0994 - mae: 0.1763 - mse: 0.0994 - val_loss: 0.0991 - val_mae: 0.2205 - val_mse: 0.0991\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.0852 - mae: 0.1702 - mse: 0.0852 - val_loss: 0.0857 - val_mae: 0.1972 - val_mse: 0.0857\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0724 - mae: 0.1562 - mse: 0.0724 - val_loss: 0.1103 - val_mae: 0.2216 - val_mse: 0.1103\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0605 - mae: 0.1465 - mse: 0.0605 - val_loss: 0.0921 - val_mae: 0.2023 - val_mse: 0.0921\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 167us/sample - loss: 0.0506 - mae: 0.1403 - mse: 0.0506 - val_loss: 0.0910 - val_mae: 0.2088 - val_mse: 0.0910\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0411 - mae: 0.1318 - mse: 0.0411 - val_loss: 0.0886 - val_mae: 0.1972 - val_mse: 0.0886\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.0369 - mae: 0.1255 - mse: 0.0369 - val_loss: 0.0965 - val_mae: 0.1988 - val_mse: 0.0965\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0280 - mae: 0.1127 - mse: 0.0280 - val_loss: 0.0913 - val_mae: 0.1995 - val_mse: 0.0913\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0270 - mae: 0.1157 - mse: 0.0270 - val_loss: 0.1006 - val_mae: 0.1980 - val_mse: 0.1006\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0272 - mae: 0.1139 - mse: 0.0272 - val_loss: 0.0887 - val_mae: 0.1922 - val_mse: 0.0887\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 168us/sample - loss: 0.0183 - mae: 0.0957 - mse: 0.0183 - val_loss: 0.0984 - val_mae: 0.1941 - val_mse: 0.0984\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 166us/sample - loss: 0.0210 - mae: 0.1038 - mse: 0.0210 - val_loss: 0.1108 - val_mae: 0.2110 - val_mse: 0.1108\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.0221 - mae: 0.1044 - mse: 0.0221 - val_loss: 0.0935 - val_mae: 0.1932 - val_mse: 0.0935\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0162 - mae: 0.0902 - mse: 0.0162 - val_loss: 0.0868 - val_mae: 0.1935 - val_mse: 0.0868\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0177 - mae: 0.0969 - mse: 0.0177 - val_loss: 0.0922 - val_mae: 0.1893 - val_mse: 0.0922\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0165 - mae: 0.0930 - mse: 0.0165 - val_loss: 0.0905 - val_mae: 0.1934 - val_mse: 0.0905\n",
            "Epoch 21/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0158 - mae: 0.0867 - mse: 0.0158 - val_loss: 0.1200 - val_mae: 0.2488 - val_mse: 0.1200\n",
            "Epoch 22/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0127 - mae: 0.0834 - mse: 0.0127 - val_loss: 0.1002 - val_mae: 0.2008 - val_mse: 0.1002\n",
            "Epoch 23/200\n",
            "1022/1022 [==============================] - 0s 166us/sample - loss: 0.0159 - mae: 0.0882 - mse: 0.0159 - val_loss: 0.0946 - val_mae: 0.1952 - val_mse: 0.0946\n",
            "Epoch 24/200\n",
            "1022/1022 [==============================] - 0s 186us/sample - loss: 0.0136 - mae: 0.0835 - mse: 0.0136 - val_loss: 0.0932 - val_mae: 0.1923 - val_mse: 0.0932\n",
            "Epoch 25/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0143 - mae: 0.0803 - mse: 0.0143 - val_loss: 0.0973 - val_mae: 0.2038 - val_mse: 0.0973\n",
            "Epoch 26/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0130 - mae: 0.0846 - mse: 0.0130 - val_loss: 0.1010 - val_mae: 0.2019 - val_mse: 0.1010\n",
            "Epoch 27/200\n",
            "1022/1022 [==============================] - 0s 169us/sample - loss: 0.0115 - mae: 0.0782 - mse: 0.0115 - val_loss: 0.1017 - val_mae: 0.2154 - val_mse: 0.1017\n",
            "Epoch 28/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0110 - mae: 0.0764 - mse: 0.0110 - val_loss: 0.0924 - val_mae: 0.2003 - val_mse: 0.0924\n",
            "Epoch 29/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0124 - mae: 0.0776 - mse: 0.0124 - val_loss: 0.0889 - val_mae: 0.1908 - val_mse: 0.0889\n",
            "Epoch 30/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0111 - mae: 0.0733 - mse: 0.0111 - val_loss: 0.1090 - val_mae: 0.2054 - val_mse: 0.1090\n",
            "Epoch 31/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0106 - mae: 0.0759 - mse: 0.0106 - val_loss: 0.1003 - val_mae: 0.2030 - val_mse: 0.1003\n",
            "Epoch 32/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0106 - mae: 0.0711 - mse: 0.0106 - val_loss: 0.0957 - val_mae: 0.2050 - val_mse: 0.0957\n",
            "Epoch 33/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0116 - mae: 0.0780 - mse: 0.0116 - val_loss: 0.0902 - val_mae: 0.1984 - val_mse: 0.0902\n",
            "Epoch 34/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.0089 - mae: 0.0662 - mse: 0.0089 - val_loss: 0.0958 - val_mae: 0.2025 - val_mse: 0.0958\n",
            "Epoch 35/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0093 - mae: 0.0657 - mse: 0.0093 - val_loss: 0.1037 - val_mae: 0.2123 - val_mse: 0.1037\n",
            "Epoch 36/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0090 - mae: 0.0676 - mse: 0.0090 - val_loss: 0.0897 - val_mae: 0.1947 - val_mse: 0.0897\n",
            "Epoch 37/200\n",
            "1022/1022 [==============================] - 0s 169us/sample - loss: 0.0101 - mae: 0.0740 - mse: 0.0101 - val_loss: 0.0924 - val_mae: 0.1958 - val_mse: 0.0924\n",
            "Epoch 38/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0085 - mae: 0.0639 - mse: 0.0085 - val_loss: 0.1030 - val_mae: 0.2090 - val_mse: 0.1030\n",
            "Epoch 39/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0098 - mae: 0.0687 - mse: 0.0098 - val_loss: 0.1061 - val_mae: 0.2111 - val_mse: 0.1061\n",
            "Epoch 40/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0092 - mae: 0.0638 - mse: 0.0092 - val_loss: 0.0930 - val_mae: 0.1983 - val_mse: 0.0930\n",
            "Epoch 41/200\n",
            "1022/1022 [==============================] - 0s 185us/sample - loss: 0.0099 - mae: 0.0712 - mse: 0.0099 - val_loss: 0.0897 - val_mae: 0.1949 - val_mse: 0.0897\n",
            "Epoch 42/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0061 - mae: 0.0551 - mse: 0.0061 - val_loss: 0.1161 - val_mae: 0.2196 - val_mse: 0.1161\n",
            "Epoch 43/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0103 - mae: 0.0632 - mse: 0.0103 - val_loss: 0.0903 - val_mae: 0.1938 - val_mse: 0.0903\n",
            "Epoch 44/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0075 - mae: 0.0620 - mse: 0.0075 - val_loss: 0.0877 - val_mae: 0.1942 - val_mse: 0.0877\n",
            "Epoch 45/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0068 - mae: 0.0594 - mse: 0.0068 - val_loss: 0.1064 - val_mae: 0.2257 - val_mse: 0.1064\n",
            "Epoch 46/200\n",
            "1022/1022 [==============================] - 0s 186us/sample - loss: 0.0094 - mae: 0.0662 - mse: 0.0094 - val_loss: 0.0917 - val_mae: 0.1974 - val_mse: 0.0917\n",
            "Epoch 47/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.0098 - mae: 0.0678 - mse: 0.0098 - val_loss: 0.0974 - val_mae: 0.2034 - val_mse: 0.0974\n",
            "Epoch 48/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0070 - mae: 0.0598 - mse: 0.0070 - val_loss: 0.0969 - val_mae: 0.2004 - val_mse: 0.0969\n",
            "Epoch 49/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0092 - mae: 0.0636 - mse: 0.0092 - val_loss: 0.1005 - val_mae: 0.2111 - val_mse: 0.1005\n",
            "Epoch 50/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0054 - mae: 0.0535 - mse: 0.0054 - val_loss: 0.0914 - val_mae: 0.1980 - val_mse: 0.0914\n",
            "Epoch 51/200\n",
            "1022/1022 [==============================] - 0s 191us/sample - loss: 0.0081 - mae: 0.0610 - mse: 0.0081 - val_loss: 0.1249 - val_mae: 0.2278 - val_mse: 0.1249\n",
            "Epoch 52/200\n",
            "1022/1022 [==============================] - 0s 190us/sample - loss: 0.0078 - mae: 0.0582 - mse: 0.0078 - val_loss: 0.1031 - val_mae: 0.2189 - val_mse: 0.1031\n",
            "Epoch 53/200\n",
            "1022/1022 [==============================] - 0s 201us/sample - loss: 0.0062 - mae: 0.0563 - mse: 0.0062 - val_loss: 0.0950 - val_mae: 0.1965 - val_mse: 0.0950\n",
            "Epoch 54/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.0070 - mae: 0.0600 - mse: 0.0070 - val_loss: 0.1008 - val_mae: 0.2148 - val_mse: 0.1008\n",
            "Epoch 55/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0058 - mae: 0.0531 - mse: 0.0058 - val_loss: 0.0999 - val_mae: 0.2059 - val_mse: 0.0999\n",
            "Epoch 56/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0101 - mae: 0.0679 - mse: 0.0101 - val_loss: 0.0925 - val_mae: 0.1972 - val_mse: 0.0925\n",
            "Epoch 57/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.0055 - mae: 0.0500 - mse: 0.0055 - val_loss: 0.0878 - val_mae: 0.1971 - val_mse: 0.0878\n",
            "Epoch 58/200\n",
            "1022/1022 [==============================] - 0s 189us/sample - loss: 0.0066 - mae: 0.0557 - mse: 0.0066 - val_loss: 0.0909 - val_mae: 0.1962 - val_mse: 0.0909\n",
            "Epoch 59/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0068 - mae: 0.0577 - mse: 0.0068 - val_loss: 0.0955 - val_mae: 0.1964 - val_mse: 0.0955\n",
            "Epoch 60/200\n",
            "1022/1022 [==============================] - 0s 195us/sample - loss: 0.0053 - mae: 0.0535 - mse: 0.0053 - val_loss: 0.0945 - val_mae: 0.1928 - val_mse: 0.0945\n",
            "Epoch 61/200\n",
            "1022/1022 [==============================] - 0s 189us/sample - loss: 0.0062 - mae: 0.0573 - mse: 0.0062 - val_loss: 0.0958 - val_mae: 0.2053 - val_mse: 0.0958\n",
            "Epoch 62/200\n",
            "1022/1022 [==============================] - 0s 193us/sample - loss: 0.0063 - mae: 0.0558 - mse: 0.0063 - val_loss: 0.0862 - val_mae: 0.1930 - val_mse: 0.0862\n",
            "Epoch 63/200\n",
            "1022/1022 [==============================] - 0s 196us/sample - loss: 0.0069 - mae: 0.0573 - mse: 0.0069 - val_loss: 0.1041 - val_mae: 0.2021 - val_mse: 0.1041\n",
            "Epoch 64/200\n",
            "1022/1022 [==============================] - 0s 191us/sample - loss: 0.0065 - mae: 0.0537 - mse: 0.0065 - val_loss: 0.0908 - val_mae: 0.1989 - val_mse: 0.0908\n",
            "Epoch 65/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.0062 - mae: 0.0553 - mse: 0.0062 - val_loss: 0.0982 - val_mae: 0.1986 - val_mse: 0.0982\n",
            "Epoch 66/200\n",
            "1022/1022 [==============================] - 0s 188us/sample - loss: 0.0075 - mae: 0.0569 - mse: 0.0075 - val_loss: 0.0927 - val_mae: 0.1962 - val_mse: 0.0927\n",
            "Epoch 67/200\n",
            "1022/1022 [==============================] - 0s 204us/sample - loss: 0.0067 - mae: 0.0578 - mse: 0.0067 - val_loss: 0.0894 - val_mae: 0.1962 - val_mse: 0.0894\n",
            "Epoch 68/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.0058 - mae: 0.0494 - mse: 0.0058 - val_loss: 0.0892 - val_mae: 0.1955 - val_mse: 0.0892\n",
            "Epoch 69/200\n",
            "1022/1022 [==============================] - 0s 190us/sample - loss: 0.0058 - mae: 0.0526 - mse: 0.0058 - val_loss: 0.1019 - val_mae: 0.1982 - val_mse: 0.1019\n",
            "Epoch 70/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0063 - mae: 0.0503 - mse: 0.0063 - val_loss: 0.0938 - val_mae: 0.1988 - val_mse: 0.0938\n",
            "Epoch 71/200\n",
            "1022/1022 [==============================] - 0s 186us/sample - loss: 0.0046 - mae: 0.0492 - mse: 0.0046 - val_loss: 0.0928 - val_mae: 0.1959 - val_mse: 0.0928\n",
            "Epoch 72/200\n",
            "1022/1022 [==============================] - 0s 193us/sample - loss: 0.0068 - mae: 0.0561 - mse: 0.0068 - val_loss: 0.0922 - val_mae: 0.1921 - val_mse: 0.0922\n",
            "Epoch 73/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.0058 - mae: 0.0492 - mse: 0.0058 - val_loss: 0.0945 - val_mae: 0.1962 - val_mse: 0.0945\n",
            "Epoch 74/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0060 - mae: 0.0526 - mse: 0.0060 - val_loss: 0.0934 - val_mae: 0.1972 - val_mse: 0.0934\n",
            "Epoch 75/200\n",
            "1022/1022 [==============================] - 0s 191us/sample - loss: 0.0048 - mae: 0.0514 - mse: 0.0048 - val_loss: 0.0964 - val_mae: 0.2003 - val_mse: 0.0964\n",
            "Epoch 76/200\n",
            "1022/1022 [==============================] - 0s 192us/sample - loss: 0.0053 - mae: 0.0506 - mse: 0.0053 - val_loss: 0.0993 - val_mae: 0.2008 - val_mse: 0.0993\n",
            "Epoch 77/200\n",
            "1022/1022 [==============================] - 0s 189us/sample - loss: 0.0056 - mae: 0.0506 - mse: 0.0056 - val_loss: 0.0938 - val_mae: 0.1994 - val_mse: 0.0938\n",
            "Epoch 78/200\n",
            "1022/1022 [==============================] - 0s 191us/sample - loss: 0.0057 - mae: 0.0552 - mse: 0.0057 - val_loss: 0.0980 - val_mae: 0.2031 - val_mse: 0.0980\n",
            "Epoch 79/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0056 - mae: 0.0517 - mse: 0.0056 - val_loss: 0.0908 - val_mae: 0.2001 - val_mse: 0.0908\n",
            "Epoch 80/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0057 - mae: 0.0510 - mse: 0.0057 - val_loss: 0.0896 - val_mae: 0.1947 - val_mse: 0.0896\n",
            "Epoch 81/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0046 - mae: 0.0471 - mse: 0.0046 - val_loss: 0.1000 - val_mae: 0.2049 - val_mse: 0.1000\n",
            "Epoch 82/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.0050 - mae: 0.0505 - mse: 0.0050 - val_loss: 0.1075 - val_mae: 0.2098 - val_mse: 0.1075\n",
            "Epoch 83/200\n",
            "1022/1022 [==============================] - 0s 217us/sample - loss: 0.0050 - mae: 0.0467 - mse: 0.0050 - val_loss: 0.0999 - val_mae: 0.2061 - val_mse: 0.0999\n",
            "Epoch 84/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0072 - mae: 0.0519 - mse: 0.0072 - val_loss: 0.0937 - val_mae: 0.1978 - val_mse: 0.0937\n",
            "Epoch 85/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0040 - mae: 0.0437 - mse: 0.0040 - val_loss: 0.0922 - val_mae: 0.1963 - val_mse: 0.0922\n",
            "Epoch 86/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0052 - mae: 0.0517 - mse: 0.0052 - val_loss: 0.1031 - val_mae: 0.2053 - val_mse: 0.1031\n",
            "Epoch 87/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.0055 - mae: 0.0497 - mse: 0.0055 - val_loss: 0.0923 - val_mae: 0.1958 - val_mse: 0.0923\n",
            "Epoch 88/200\n",
            "1022/1022 [==============================] - 0s 162us/sample - loss: 0.0048 - mae: 0.0489 - mse: 0.0048 - val_loss: 0.0892 - val_mae: 0.1899 - val_mse: 0.0892\n",
            "Epoch 89/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0049 - mae: 0.0507 - mse: 0.0049 - val_loss: 0.0910 - val_mae: 0.1933 - val_mse: 0.0910\n",
            "Epoch 90/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0046 - mae: 0.0480 - mse: 0.0046 - val_loss: 0.0947 - val_mae: 0.2043 - val_mse: 0.0947\n",
            "Epoch 91/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0043 - mae: 0.0460 - mse: 0.0043 - val_loss: 0.0923 - val_mae: 0.1963 - val_mse: 0.0923\n",
            "Epoch 92/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0052 - mae: 0.0458 - mse: 0.0052 - val_loss: 0.0939 - val_mae: 0.1970 - val_mse: 0.0939\n",
            "Epoch 93/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0047 - mae: 0.0473 - mse: 0.0047 - val_loss: 0.0987 - val_mae: 0.2065 - val_mse: 0.0987\n",
            "Epoch 94/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0047 - mae: 0.0477 - mse: 0.0047 - val_loss: 0.0872 - val_mae: 0.1911 - val_mse: 0.0872\n",
            "Epoch 95/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0039 - mae: 0.0437 - mse: 0.0039 - val_loss: 0.0934 - val_mae: 0.1924 - val_mse: 0.0934\n",
            "Epoch 96/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0063 - mae: 0.0516 - mse: 0.0063 - val_loss: 0.0922 - val_mae: 0.1978 - val_mse: 0.0922\n",
            "Epoch 97/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0040 - mae: 0.0440 - mse: 0.0040 - val_loss: 0.0986 - val_mae: 0.1974 - val_mse: 0.0986\n",
            "Epoch 98/200\n",
            "1022/1022 [==============================] - 0s 163us/sample - loss: 0.0041 - mae: 0.0438 - mse: 0.0041 - val_loss: 0.0916 - val_mae: 0.1963 - val_mse: 0.0916\n",
            "Epoch 99/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0048 - mae: 0.0470 - mse: 0.0048 - val_loss: 0.0917 - val_mae: 0.1950 - val_mse: 0.0917\n",
            "Epoch 100/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0042 - mae: 0.0448 - mse: 0.0042 - val_loss: 0.1133 - val_mae: 0.2181 - val_mse: 0.1133\n",
            "Epoch 101/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0047 - mae: 0.0442 - mse: 0.0047 - val_loss: 0.0927 - val_mae: 0.1958 - val_mse: 0.0927\n",
            "Epoch 102/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0057 - mae: 0.0495 - mse: 0.0057 - val_loss: 0.0897 - val_mae: 0.1912 - val_mse: 0.0897\n",
            "Epoch 103/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0037 - mae: 0.0425 - mse: 0.0037 - val_loss: 0.0881 - val_mae: 0.1898 - val_mse: 0.0881\n",
            "Epoch 104/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.0048 - mae: 0.0449 - mse: 0.0048 - val_loss: 0.0866 - val_mae: 0.1911 - val_mse: 0.0866\n",
            "Epoch 105/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0040 - mae: 0.0432 - mse: 0.0040 - val_loss: 0.0915 - val_mae: 0.1944 - val_mse: 0.0915\n",
            "Epoch 106/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0036 - mae: 0.0425 - mse: 0.0036 - val_loss: 0.0872 - val_mae: 0.1895 - val_mse: 0.0872\n",
            "Epoch 107/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0041 - mae: 0.0443 - mse: 0.0041 - val_loss: 0.0872 - val_mae: 0.1883 - val_mse: 0.0872\n",
            "Epoch 108/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0051 - mae: 0.0466 - mse: 0.0051 - val_loss: 0.0909 - val_mae: 0.1945 - val_mse: 0.0909\n",
            "Epoch 109/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.0050 - mae: 0.0460 - mse: 0.0050 - val_loss: 0.0919 - val_mae: 0.1941 - val_mse: 0.0919\n",
            "Epoch 110/200\n",
            "1022/1022 [==============================] - 0s 204us/sample - loss: 0.0051 - mae: 0.0484 - mse: 0.0051 - val_loss: 0.0913 - val_mae: 0.1926 - val_mse: 0.0913\n",
            "Epoch 111/200\n",
            "1022/1022 [==============================] - 0s 191us/sample - loss: 0.0033 - mae: 0.0389 - mse: 0.0033 - val_loss: 0.0994 - val_mae: 0.2034 - val_mse: 0.0994\n",
            "Epoch 112/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0051 - mae: 0.0465 - mse: 0.0051 - val_loss: 0.0900 - val_mae: 0.1952 - val_mse: 0.0900\n",
            "Epoch 113/200\n",
            "1022/1022 [==============================] - 0s 167us/sample - loss: 0.0046 - mae: 0.0456 - mse: 0.0046 - val_loss: 0.0905 - val_mae: 0.1944 - val_mse: 0.0905\n",
            "Epoch 114/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0029 - mae: 0.0388 - mse: 0.0029 - val_loss: 0.0899 - val_mae: 0.1954 - val_mse: 0.0899\n",
            "Epoch 115/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0042 - mae: 0.0456 - mse: 0.0042 - val_loss: 0.0952 - val_mae: 0.1930 - val_mse: 0.0952\n",
            "Epoch 116/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0051 - mae: 0.0467 - mse: 0.0051 - val_loss: 0.0901 - val_mae: 0.1945 - val_mse: 0.0901\n",
            "Epoch 117/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0039 - mae: 0.0416 - mse: 0.0039 - val_loss: 0.0929 - val_mae: 0.1945 - val_mse: 0.0929\n",
            "Epoch 118/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0051 - mae: 0.0468 - mse: 0.0051 - val_loss: 0.0937 - val_mae: 0.1925 - val_mse: 0.0937\n",
            "Epoch 119/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0037 - mae: 0.0409 - mse: 0.0037 - val_loss: 0.0902 - val_mae: 0.1931 - val_mse: 0.0902\n",
            "Epoch 120/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.0039 - mae: 0.0406 - mse: 0.0039 - val_loss: 0.0917 - val_mae: 0.1960 - val_mse: 0.0917\n",
            "Epoch 121/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0043 - mae: 0.0413 - mse: 0.0043 - val_loss: 0.0921 - val_mae: 0.1929 - val_mse: 0.0921\n",
            "Epoch 122/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0045 - mae: 0.0466 - mse: 0.0045 - val_loss: 0.0853 - val_mae: 0.1889 - val_mse: 0.0853\n",
            "Epoch 123/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0031 - mae: 0.0396 - mse: 0.0031 - val_loss: 0.0969 - val_mae: 0.1978 - val_mse: 0.0969\n",
            "Epoch 124/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0046 - mae: 0.0464 - mse: 0.0046 - val_loss: 0.0868 - val_mae: 0.1887 - val_mse: 0.0868\n",
            "Epoch 125/200\n",
            "1022/1022 [==============================] - 0s 185us/sample - loss: 0.0038 - mae: 0.0428 - mse: 0.0038 - val_loss: 0.0921 - val_mae: 0.2008 - val_mse: 0.0921\n",
            "Epoch 126/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0037 - mae: 0.0406 - mse: 0.0037 - val_loss: 0.0852 - val_mae: 0.1895 - val_mse: 0.0852\n",
            "Epoch 127/200\n",
            "1022/1022 [==============================] - 0s 167us/sample - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.1036 - val_mae: 0.2206 - val_mse: 0.1036\n",
            "Epoch 128/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0038 - mae: 0.0428 - mse: 0.0038 - val_loss: 0.0895 - val_mae: 0.1910 - val_mse: 0.0895\n",
            "Epoch 129/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0037 - mae: 0.0404 - mse: 0.0037 - val_loss: 0.0896 - val_mae: 0.1901 - val_mse: 0.0896\n",
            "Epoch 130/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0044 - mae: 0.0422 - mse: 0.0044 - val_loss: 0.0935 - val_mae: 0.1924 - val_mse: 0.0935\n",
            "Epoch 131/200\n",
            "1022/1022 [==============================] - 0s 168us/sample - loss: 0.0046 - mae: 0.0430 - mse: 0.0046 - val_loss: 0.0877 - val_mae: 0.1920 - val_mse: 0.0877\n",
            "Epoch 132/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0032 - mae: 0.0384 - mse: 0.0032 - val_loss: 0.0934 - val_mae: 0.1971 - val_mse: 0.0934\n",
            "Epoch 133/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0042 - mae: 0.0438 - mse: 0.0042 - val_loss: 0.0920 - val_mae: 0.1957 - val_mse: 0.0920\n",
            "Epoch 134/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0034 - mae: 0.0392 - mse: 0.0034 - val_loss: 0.0972 - val_mae: 0.1938 - val_mse: 0.0972\n",
            "Epoch 135/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0029 - mae: 0.0386 - mse: 0.0029 - val_loss: 0.0913 - val_mae: 0.1923 - val_mse: 0.0913\n",
            "Epoch 136/200\n",
            "1022/1022 [==============================] - 0s 167us/sample - loss: 0.0037 - mae: 0.0402 - mse: 0.0037 - val_loss: 0.0939 - val_mae: 0.1919 - val_mse: 0.0939\n",
            "Epoch 137/200\n",
            "1022/1022 [==============================] - 0s 167us/sample - loss: 0.0038 - mae: 0.0437 - mse: 0.0038 - val_loss: 0.0911 - val_mae: 0.1918 - val_mse: 0.0911\n",
            "Epoch 138/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0041 - mae: 0.0409 - mse: 0.0041 - val_loss: 0.0910 - val_mae: 0.1932 - val_mse: 0.0910\n",
            "Epoch 139/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0030 - mae: 0.0397 - mse: 0.0030 - val_loss: 0.0899 - val_mae: 0.1906 - val_mse: 0.0899\n",
            "Epoch 140/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0038 - mae: 0.0419 - mse: 0.0038 - val_loss: 0.0901 - val_mae: 0.1929 - val_mse: 0.0901\n",
            "Epoch 141/200\n",
            "1022/1022 [==============================] - 0s 169us/sample - loss: 0.0032 - mae: 0.0384 - mse: 0.0032 - val_loss: 0.0931 - val_mae: 0.1928 - val_mse: 0.0931\n",
            "Epoch 142/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0038 - mae: 0.0409 - mse: 0.0038 - val_loss: 0.0930 - val_mae: 0.1983 - val_mse: 0.0930\n",
            "Epoch 143/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0034 - mae: 0.0409 - mse: 0.0034 - val_loss: 0.0919 - val_mae: 0.1919 - val_mse: 0.0919\n",
            "Epoch 144/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0036 - mae: 0.0387 - mse: 0.0036 - val_loss: 0.0886 - val_mae: 0.1917 - val_mse: 0.0886\n",
            "Epoch 145/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.0031 - mae: 0.0397 - mse: 0.0031 - val_loss: 0.0958 - val_mae: 0.1966 - val_mse: 0.0958\n",
            "Epoch 146/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0033 - mae: 0.0404 - mse: 0.0033 - val_loss: 0.0861 - val_mae: 0.1892 - val_mse: 0.0861\n",
            "Epoch 147/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0043 - mae: 0.0410 - mse: 0.0043 - val_loss: 0.0922 - val_mae: 0.1960 - val_mse: 0.0922\n",
            "Epoch 148/200\n",
            "1022/1022 [==============================] - 0s 165us/sample - loss: 0.0028 - mae: 0.0360 - mse: 0.0028 - val_loss: 0.0877 - val_mae: 0.1946 - val_mse: 0.0877\n",
            "Epoch 149/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0036 - mae: 0.0394 - mse: 0.0036 - val_loss: 0.0959 - val_mae: 0.1970 - val_mse: 0.0959\n",
            "Epoch 150/200\n",
            "1022/1022 [==============================] - 0s 167us/sample - loss: 0.0038 - mae: 0.0416 - mse: 0.0038 - val_loss: 0.0889 - val_mae: 0.1914 - val_mse: 0.0889\n",
            "Epoch 151/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0930 - val_mae: 0.1945 - val_mse: 0.0930\n",
            "Epoch 152/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0038 - mae: 0.0404 - mse: 0.0038 - val_loss: 0.0944 - val_mae: 0.1985 - val_mse: 0.0944\n",
            "Epoch 153/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0031 - mae: 0.0375 - mse: 0.0031 - val_loss: 0.0907 - val_mae: 0.1924 - val_mse: 0.0907\n",
            "Epoch 154/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0037 - mae: 0.0402 - mse: 0.0037 - val_loss: 0.0871 - val_mae: 0.1913 - val_mse: 0.0871\n",
            "Epoch 155/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0028 - mae: 0.0353 - mse: 0.0028 - val_loss: 0.0922 - val_mae: 0.1950 - val_mse: 0.0922\n",
            "Epoch 156/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0029 - mae: 0.0377 - mse: 0.0029 - val_loss: 0.0916 - val_mae: 0.1954 - val_mse: 0.0916\n",
            "Epoch 157/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.0039 - mae: 0.0434 - mse: 0.0039 - val_loss: 0.0861 - val_mae: 0.1886 - val_mse: 0.0861\n",
            "Epoch 158/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.0035 - mae: 0.0376 - mse: 0.0035 - val_loss: 0.0873 - val_mae: 0.1916 - val_mse: 0.0873\n",
            "Epoch 159/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0029 - mae: 0.0378 - mse: 0.0029 - val_loss: 0.0899 - val_mae: 0.1921 - val_mse: 0.0899\n",
            "Epoch 160/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.0031 - mae: 0.0396 - mse: 0.0031 - val_loss: 0.0969 - val_mae: 0.2056 - val_mse: 0.0969\n",
            "Epoch 161/200\n",
            "1022/1022 [==============================] - 0s 169us/sample - loss: 0.0038 - mae: 0.0421 - mse: 0.0038 - val_loss: 0.0946 - val_mae: 0.1932 - val_mse: 0.0946\n",
            "Epoch 162/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0936 - val_mae: 0.2029 - val_mse: 0.0936\n",
            "Epoch 163/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0032 - mae: 0.0363 - mse: 0.0032 - val_loss: 0.0973 - val_mae: 0.1955 - val_mse: 0.0973\n",
            "Epoch 164/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0030 - mae: 0.0378 - mse: 0.0030 - val_loss: 0.0916 - val_mae: 0.1936 - val_mse: 0.0916\n",
            "Epoch 165/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0034 - mae: 0.0389 - mse: 0.0034 - val_loss: 0.0941 - val_mae: 0.1929 - val_mse: 0.0941\n",
            "Epoch 166/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0031 - mae: 0.0384 - mse: 0.0031 - val_loss: 0.0939 - val_mae: 0.1914 - val_mse: 0.0939\n",
            "Epoch 167/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0029 - mae: 0.0384 - mse: 0.0029 - val_loss: 0.0910 - val_mae: 0.1932 - val_mse: 0.0910\n",
            "Epoch 168/200\n",
            "1022/1022 [==============================] - 0s 189us/sample - loss: 0.0029 - mae: 0.0377 - mse: 0.0029 - val_loss: 0.0941 - val_mae: 0.1936 - val_mse: 0.0941\n",
            "Epoch 169/200\n",
            "1022/1022 [==============================] - 0s 202us/sample - loss: 0.0029 - mae: 0.0364 - mse: 0.0029 - val_loss: 0.0930 - val_mae: 0.1996 - val_mse: 0.0930\n",
            "Epoch 170/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0037 - mae: 0.0379 - mse: 0.0037 - val_loss: 0.0964 - val_mae: 0.2004 - val_mse: 0.0964\n",
            "Epoch 171/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.0027 - mae: 0.0352 - mse: 0.0027 - val_loss: 0.0879 - val_mae: 0.1877 - val_mse: 0.0879\n",
            "Epoch 172/200\n",
            "1022/1022 [==============================] - 0s 168us/sample - loss: 0.0038 - mae: 0.0388 - mse: 0.0038 - val_loss: 0.0948 - val_mae: 0.2007 - val_mse: 0.0948\n",
            "Epoch 173/200\n",
            "1022/1022 [==============================] - 0s 190us/sample - loss: 0.0026 - mae: 0.0320 - mse: 0.0026 - val_loss: 0.0906 - val_mae: 0.1962 - val_mse: 0.0906\n",
            "Epoch 174/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0033 - mae: 0.0384 - mse: 0.0033 - val_loss: 0.0943 - val_mae: 0.2024 - val_mse: 0.0943\n",
            "Epoch 175/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0030 - mae: 0.0380 - mse: 0.0030 - val_loss: 0.0894 - val_mae: 0.1925 - val_mse: 0.0894\n",
            "Epoch 176/200\n",
            "1022/1022 [==============================] - 0s 167us/sample - loss: 0.0028 - mae: 0.0370 - mse: 0.0028 - val_loss: 0.0905 - val_mae: 0.1917 - val_mse: 0.0905\n",
            "Epoch 177/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0033 - mae: 0.0397 - mse: 0.0033 - val_loss: 0.0909 - val_mae: 0.1907 - val_mse: 0.0909\n",
            "Epoch 178/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0031 - mae: 0.0383 - mse: 0.0031 - val_loss: 0.0895 - val_mae: 0.1908 - val_mse: 0.0895\n",
            "Epoch 179/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.0029 - mae: 0.0349 - mse: 0.0029 - val_loss: 0.0845 - val_mae: 0.1888 - val_mse: 0.0845\n",
            "Epoch 180/200\n",
            "1022/1022 [==============================] - 0s 169us/sample - loss: 0.0031 - mae: 0.0361 - mse: 0.0031 - val_loss: 0.0866 - val_mae: 0.1892 - val_mse: 0.0866\n",
            "Epoch 181/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0924 - val_mae: 0.1962 - val_mse: 0.0924\n",
            "Epoch 182/200\n",
            "1022/1022 [==============================] - 0s 169us/sample - loss: 0.0032 - mae: 0.0375 - mse: 0.0032 - val_loss: 0.0872 - val_mae: 0.1898 - val_mse: 0.0872\n",
            "Epoch 183/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0869 - val_mae: 0.1870 - val_mse: 0.0869\n",
            "Epoch 184/200\n",
            "1022/1022 [==============================] - 0s 189us/sample - loss: 0.0024 - mae: 0.0337 - mse: 0.0024 - val_loss: 0.0917 - val_mae: 0.1946 - val_mse: 0.0917\n",
            "Epoch 185/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0028 - mae: 0.0361 - mse: 0.0028 - val_loss: 0.0933 - val_mae: 0.2017 - val_mse: 0.0933\n",
            "Epoch 186/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.0029 - mae: 0.0368 - mse: 0.0029 - val_loss: 0.0907 - val_mae: 0.1931 - val_mse: 0.0907\n",
            "Epoch 187/200\n",
            "1022/1022 [==============================] - 0s 162us/sample - loss: 0.0038 - mae: 0.0385 - mse: 0.0038 - val_loss: 0.0937 - val_mae: 0.1918 - val_mse: 0.0937\n",
            "Epoch 188/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0024 - mae: 0.0338 - mse: 0.0024 - val_loss: 0.0892 - val_mae: 0.1920 - val_mse: 0.0892\n",
            "Epoch 189/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0027 - mae: 0.0353 - mse: 0.0027 - val_loss: 0.0971 - val_mae: 0.1956 - val_mse: 0.0971\n",
            "Epoch 190/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.0030 - mae: 0.0385 - mse: 0.0030 - val_loss: 0.0906 - val_mae: 0.1915 - val_mse: 0.0906\n",
            "Epoch 191/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0029 - mae: 0.0370 - mse: 0.0029 - val_loss: 0.0913 - val_mae: 0.1932 - val_mse: 0.0913\n",
            "Epoch 192/200\n",
            "1022/1022 [==============================] - 0s 163us/sample - loss: 0.0031 - mae: 0.0376 - mse: 0.0031 - val_loss: 0.0911 - val_mae: 0.1962 - val_mse: 0.0911\n",
            "Epoch 193/200\n",
            "1022/1022 [==============================] - 0s 169us/sample - loss: 0.0024 - mae: 0.0344 - mse: 0.0024 - val_loss: 0.0875 - val_mae: 0.1894 - val_mse: 0.0875\n",
            "Epoch 194/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0028 - mae: 0.0342 - mse: 0.0028 - val_loss: 0.0944 - val_mae: 0.1925 - val_mse: 0.0944\n",
            "Epoch 195/200\n",
            "1022/1022 [==============================] - 0s 166us/sample - loss: 0.0027 - mae: 0.0367 - mse: 0.0027 - val_loss: 0.0898 - val_mae: 0.1903 - val_mse: 0.0898\n",
            "Epoch 196/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0030 - mae: 0.0358 - mse: 0.0030 - val_loss: 0.0907 - val_mae: 0.1927 - val_mse: 0.0907\n",
            "Epoch 197/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0027 - mae: 0.0349 - mse: 0.0027 - val_loss: 0.0973 - val_mae: 0.1957 - val_mse: 0.0973\n",
            "Epoch 198/200\n",
            "1022/1022 [==============================] - 0s 168us/sample - loss: 0.0036 - mae: 0.0369 - mse: 0.0036 - val_loss: 0.0933 - val_mae: 0.1978 - val_mse: 0.0933\n",
            "Epoch 199/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0026 - mae: 0.0323 - mse: 0.0026 - val_loss: 0.0882 - val_mae: 0.1889 - val_mse: 0.0882\n",
            "Epoch 200/200\n",
            "1022/1022 [==============================] - 0s 180us/sample - loss: 0.0029 - mae: 0.0360 - mse: 0.0029 - val_loss: 0.0907 - val_mae: 0.1896 - val_mse: 0.0907\n",
            "Temps d'entrainement 37.6735417842865 seconds ---\n",
            "Predicting house prices model network 64 * 64 * 1\n",
            "Regression metrics for train data\n",
            "   max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  26663.125          2246.259452        1.251366e+07  0.998176\n",
            "Regression metrics for test data\n",
            "      max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  174798.21875         15705.855585        6.224749e+08  0.874368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9F0Qv3BSIoV",
        "colab_type": "text"
      },
      "source": [
        "On observe dans le cas présent un overfitting important sur le train par rapport à l'ensemble de validation. Une petite optimisation pour éviter de réaliser tous epoch est de mettre en place un callback et regarder si la fonction val_loss ne s'améliore pas de manière significative pendant une certaine période."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iKS1dVaQzm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "a9930f18-2ce6-4aa4-d220-e66259a28eed"
      },
      "source": [
        "TrainingNetwork(model_64_64_1, str(64) +\" * \" + str(64) + \" * 1\", callback=True)\n",
        "PredictionAndEvaluationNetwork(model_64_64_1, str(64) +\" * \" + str(64) + \" * 1\", callback=True)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model network 64 * 64 * 1 with Callback\n",
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0026 - mae: 0.0343 - mse: 0.0026 - val_loss: 0.0917 - val_mae: 0.1920 - val_mse: 0.0917\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0030 - mae: 0.0361 - mse: 0.0030 - val_loss: 0.0904 - val_mae: 0.1912 - val_mse: 0.0904\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0024 - mae: 0.0346 - mse: 0.0024 - val_loss: 0.0887 - val_mae: 0.1906 - val_mse: 0.0887\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0029 - mae: 0.0335 - mse: 0.0029 - val_loss: 0.0941 - val_mae: 0.1970 - val_mse: 0.0941\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.0024 - mae: 0.0331 - mse: 0.0024 - val_loss: 0.0908 - val_mae: 0.1955 - val_mse: 0.0908\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0032 - mae: 0.0367 - mse: 0.0032 - val_loss: 0.0927 - val_mae: 0.1958 - val_mse: 0.0927\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0023 - mae: 0.0340 - mse: 0.0023 - val_loss: 0.0908 - val_mae: 0.1893 - val_mse: 0.0908\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0029 - mae: 0.0353 - mse: 0.0029 - val_loss: 0.0920 - val_mae: 0.1914 - val_mse: 0.0920\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.0032 - mae: 0.0384 - mse: 0.0032 - val_loss: 0.0904 - val_mae: 0.1921 - val_mse: 0.0904\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.0027 - mae: 0.0323 - mse: 0.0027 - val_loss: 0.0949 - val_mae: 0.1936 - val_mse: 0.0949\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.0026 - mae: 0.0330 - mse: 0.0026 - val_loss: 0.0959 - val_mae: 0.1959 - val_mse: 0.0959\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0028 - mae: 0.0361 - mse: 0.0028 - val_loss: 0.0961 - val_mae: 0.1925 - val_mse: 0.0961\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 175us/sample - loss: 0.0028 - mae: 0.0356 - mse: 0.0028 - val_loss: 0.0930 - val_mae: 0.1971 - val_mse: 0.0930\n",
            "Temps d'entrainement 2.4259743690490723 seconds ---\n",
            "Predicting house prices model network 64 * 64 * 1 with Callback\n",
            "Regression metrics for train data\n",
            "   max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  34777.875          3725.107655        2.359833e+07  0.996561\n",
            "Regression metrics for test data\n",
            "      max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  176722.03125         16326.826359        6.383168e+08  0.871171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD6K3JsKZWa3",
        "colab_type": "text"
      },
      "source": [
        "On observe toujours un overfitting important avec cette architecture malgré la mise en place du callback qui a juste limité le nombre d'epoch dans le cas présent mais aurait pu dans d'autres cas limiter le surapprentissage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVa_syoJp2Ei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "b049a9fc-b2c3-48b0-f796-f9216a1bce8d"
      },
      "source": [
        "print(\"Prise en compte du dropout dans le training dans les couches cachées avec rate = 30%\")\n",
        "TrainingNetwork(model_64_64_1_DropOut, str(64) +\" * \" + str(64) + \" * 1\", callback=True)\n",
        "PredictionAndEvaluationNetwork(model_64_64_1_DropOut, str(64) +\" * \" + str(64) + \" * 1\", callback=True)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prise en compte du dropout dans le training dans les couches cachées avec rate = 30%\n",
            "Training model network 64 * 64 * 1 with Callback\n",
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 751us/sample - loss: 0.5699 - mae: 0.5310 - mse: 0.5699 - val_loss: 0.1542 - val_mae: 0.2986 - val_mse: 0.1542\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.4198 - mae: 0.4317 - mse: 0.4198 - val_loss: 0.1102 - val_mae: 0.2495 - val_mse: 0.1102\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.3169 - mae: 0.3698 - mse: 0.3169 - val_loss: 0.1190 - val_mae: 0.2743 - val_mse: 0.1190\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.3074 - mae: 0.3514 - mse: 0.3074 - val_loss: 0.0992 - val_mae: 0.2383 - val_mse: 0.0992\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 188us/sample - loss: 0.3435 - mae: 0.3475 - mse: 0.3435 - val_loss: 0.0842 - val_mae: 0.2131 - val_mse: 0.0842\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.2440 - mae: 0.3234 - mse: 0.2440 - val_loss: 0.0915 - val_mae: 0.2361 - val_mse: 0.0915\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 209us/sample - loss: 0.2067 - mae: 0.2933 - mse: 0.2067 - val_loss: 0.0831 - val_mae: 0.2160 - val_mse: 0.0831\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.2082 - mae: 0.2833 - mse: 0.2082 - val_loss: 0.0900 - val_mae: 0.2262 - val_mse: 0.0900\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 186us/sample - loss: 0.2820 - mae: 0.2925 - mse: 0.2820 - val_loss: 0.0838 - val_mae: 0.2159 - val_mse: 0.0838\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 185us/sample - loss: 0.2313 - mae: 0.2814 - mse: 0.2313 - val_loss: 0.0872 - val_mae: 0.2210 - val_mse: 0.0872\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.2466 - mae: 0.2740 - mse: 0.2466 - val_loss: 0.0792 - val_mae: 0.2096 - val_mse: 0.0792\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.1893 - mae: 0.2578 - mse: 0.1893 - val_loss: 0.1038 - val_mae: 0.2479 - val_mse: 0.1038\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.1907 - mae: 0.2636 - mse: 0.1907 - val_loss: 0.1002 - val_mae: 0.2312 - val_mse: 0.1002\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.1935 - mae: 0.2533 - mse: 0.1935 - val_loss: 0.0944 - val_mae: 0.2293 - val_mse: 0.0944\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.1789 - mae: 0.2441 - mse: 0.1789 - val_loss: 0.0940 - val_mae: 0.2238 - val_mse: 0.0940\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 194us/sample - loss: 0.1749 - mae: 0.2486 - mse: 0.1749 - val_loss: 0.0978 - val_mae: 0.2282 - val_mse: 0.0978\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.1592 - mae: 0.2328 - mse: 0.1592 - val_loss: 0.1054 - val_mae: 0.2291 - val_mse: 0.1054\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.1568 - mae: 0.2298 - mse: 0.1568 - val_loss: 0.0994 - val_mae: 0.2243 - val_mse: 0.0994\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.1380 - mae: 0.2233 - mse: 0.1380 - val_loss: 0.1076 - val_mae: 0.2451 - val_mse: 0.1076\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.1406 - mae: 0.2333 - mse: 0.1406 - val_loss: 0.0940 - val_mae: 0.2178 - val_mse: 0.0940\n",
            "Epoch 21/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.1672 - mae: 0.2323 - mse: 0.1672 - val_loss: 0.0948 - val_mae: 0.2216 - val_mse: 0.0948\n",
            "Temps d'entrainement 4.6166205406188965 seconds ---\n",
            "Predicting house prices model network 64 * 64 * 1 with Callback\n",
            "Regression metrics for train data\n",
            "      max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  227672.40625         14635.128054        5.044233e+08  0.926481\n",
            "Regression metrics for test data\n",
            "     max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  185090.8125         18352.437768        6.505461e+08  0.868703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li4s1wIAkDW8",
        "colab_type": "text"
      },
      "source": [
        "On observe toujours un peu de surapprentissage mais de manière moindre grâce au dropout. Je me suis inspiré pour partie : https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCKdM2SZFHqw",
        "colab_type": "text"
      },
      "source": [
        "### Modèle avec 2 couches cachées et 32 neurones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVkdFGl3qyY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "7783489b-d745-4c10-9fe2-5972bb5aa36c"
      },
      "source": [
        "TrainingNetwork(model_32_32_1, str(32) +\" * \" + str(32) + \" * 1\", callback=True)\n",
        "PredictionAndEvaluationNetwork(model_32_32_1, str(32) +\" * \" + str(32) + \" * 1\", callback=True)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model network 32 * 32 * 1 with Callback\n",
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 668us/sample - loss: 0.4674 - mae: 0.4134 - mse: 0.4674 - val_loss: 0.1666 - val_mae: 0.2945 - val_mse: 0.1666\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 185us/sample - loss: 0.2296 - mae: 0.2906 - mse: 0.2296 - val_loss: 0.1171 - val_mae: 0.2411 - val_mse: 0.1171\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 169us/sample - loss: 0.1916 - mae: 0.2517 - mse: 0.1916 - val_loss: 0.1024 - val_mae: 0.2256 - val_mse: 0.1024\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.1607 - mae: 0.2245 - mse: 0.1607 - val_loss: 0.1060 - val_mae: 0.2331 - val_mse: 0.1060\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 173us/sample - loss: 0.1478 - mae: 0.2071 - mse: 0.1478 - val_loss: 0.1013 - val_mae: 0.2199 - val_mse: 0.1013\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.1292 - mae: 0.1880 - mse: 0.1292 - val_loss: 0.0891 - val_mae: 0.2051 - val_mse: 0.0891\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 185us/sample - loss: 0.1140 - mae: 0.1772 - mse: 0.1140 - val_loss: 0.0868 - val_mae: 0.2023 - val_mse: 0.0868\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 168us/sample - loss: 0.1088 - mae: 0.1695 - mse: 0.1088 - val_loss: 0.0966 - val_mae: 0.2123 - val_mse: 0.0966\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0976 - mae: 0.1593 - mse: 0.0976 - val_loss: 0.0872 - val_mae: 0.1976 - val_mse: 0.0872\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 170us/sample - loss: 0.0883 - mae: 0.1539 - mse: 0.0883 - val_loss: 0.0847 - val_mae: 0.1967 - val_mse: 0.0847\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0852 - mae: 0.1436 - mse: 0.0852 - val_loss: 0.0952 - val_mae: 0.2080 - val_mse: 0.0952\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.0742 - mae: 0.1358 - mse: 0.0742 - val_loss: 0.0856 - val_mae: 0.1977 - val_mse: 0.0856\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 191us/sample - loss: 0.0745 - mae: 0.1370 - mse: 0.0745 - val_loss: 0.0872 - val_mae: 0.1949 - val_mse: 0.0872\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.0629 - mae: 0.1266 - mse: 0.0629 - val_loss: 0.0875 - val_mae: 0.1998 - val_mse: 0.0875\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.0571 - mae: 0.1235 - mse: 0.0571 - val_loss: 0.0957 - val_mae: 0.2060 - val_mse: 0.0957\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 172us/sample - loss: 0.0556 - mae: 0.1197 - mse: 0.0556 - val_loss: 0.0879 - val_mae: 0.1978 - val_mse: 0.0879\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.0475 - mae: 0.1168 - mse: 0.0475 - val_loss: 0.0931 - val_mae: 0.2043 - val_mse: 0.0931\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.0432 - mae: 0.1090 - mse: 0.0432 - val_loss: 0.1030 - val_mae: 0.2213 - val_mse: 0.1030\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 185us/sample - loss: 0.0417 - mae: 0.1066 - mse: 0.0417 - val_loss: 0.0988 - val_mae: 0.2039 - val_mse: 0.0988\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 165us/sample - loss: 0.0358 - mae: 0.1025 - mse: 0.0358 - val_loss: 0.0985 - val_mae: 0.2043 - val_mse: 0.0985\n",
            "Temps d'entrainement 4.190718650817871 seconds ---\n",
            "Predicting house prices model network 32 * 32 * 1 with Callback\n",
            "Regression metrics for train data\n",
            "     max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  201878.1875          7854.454929        1.998494e+08  0.970872\n",
            "Regression metrics for test data\n",
            "      max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  230439.34375         16918.635265        6.758928e+08  0.863587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N8IfTwGrRHC",
        "colab_type": "text"
      },
      "source": [
        "On a toujours un surpapprentissage et des différences non significatives par rapport à l'architecture 64 * 64 sur l'ensemble de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWI3bQnvrksO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bd592fb-516e-4f69-c09d-dd2b2cf76acc"
      },
      "source": [
        "print(\"Prise en compte du dropout dans le training dans les couches cachées avec rate = 30%\")\n",
        "TrainingNetwork(model_32_32_1_DropOut, str(32) +\" * \" + str(32) + \" * 1\",callback=True)\n",
        "PredictionAndEvaluationNetwork(model_32_32_1_DropOut, str(32) +\" * \" + str(32) + \" * 1\",callback=True)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prise en compte du dropout dans le training dans les couches cachées avec rate = 30%\n",
            "Training model network 32 * 32 * 1 with Callback\n",
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 751us/sample - loss: 0.9936 - mae: 0.6591 - mse: 0.9936 - val_loss: 0.3402 - val_mae: 0.4160 - val_mse: 0.3402\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 177us/sample - loss: 0.6052 - mae: 0.5163 - mse: 0.6052 - val_loss: 0.2287 - val_mae: 0.3392 - val_mse: 0.2287\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 190us/sample - loss: 0.4756 - mae: 0.4504 - mse: 0.4756 - val_loss: 0.1651 - val_mae: 0.2941 - val_mse: 0.1651\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.3830 - mae: 0.4125 - mse: 0.3830 - val_loss: 0.1335 - val_mae: 0.2541 - val_mse: 0.1335\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 190us/sample - loss: 0.3188 - mae: 0.3766 - mse: 0.3188 - val_loss: 0.1247 - val_mae: 0.2526 - val_mse: 0.1247\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 164us/sample - loss: 0.3337 - mae: 0.3521 - mse: 0.3337 - val_loss: 0.1256 - val_mae: 0.2550 - val_mse: 0.1256\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.2829 - mae: 0.3398 - mse: 0.2829 - val_loss: 0.1142 - val_mae: 0.2446 - val_mse: 0.1142\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.3674 - mae: 0.3393 - mse: 0.3674 - val_loss: 0.1217 - val_mae: 0.2469 - val_mse: 0.1217\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 174us/sample - loss: 0.2822 - mae: 0.3294 - mse: 0.2822 - val_loss: 0.1117 - val_mae: 0.2378 - val_mse: 0.1117\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 178us/sample - loss: 0.2587 - mae: 0.3137 - mse: 0.2587 - val_loss: 0.0985 - val_mae: 0.2318 - val_mse: 0.0985\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.2030 - mae: 0.3005 - mse: 0.2030 - val_loss: 0.1036 - val_mae: 0.2395 - val_mse: 0.1036\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.2256 - mae: 0.2989 - mse: 0.2256 - val_loss: 0.1014 - val_mae: 0.2361 - val_mse: 0.1014\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 179us/sample - loss: 0.3781 - mae: 0.2981 - mse: 0.3781 - val_loss: 0.0981 - val_mae: 0.2237 - val_mse: 0.0981\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 195us/sample - loss: 0.2192 - mae: 0.2806 - mse: 0.2192 - val_loss: 0.1045 - val_mae: 0.2239 - val_mse: 0.1045\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.2796 - mae: 0.2903 - mse: 0.2796 - val_loss: 0.1142 - val_mae: 0.2461 - val_mse: 0.1142\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 190us/sample - loss: 0.1791 - mae: 0.2664 - mse: 0.1791 - val_loss: 0.1001 - val_mae: 0.2346 - val_mse: 0.1001\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.2275 - mae: 0.2729 - mse: 0.2275 - val_loss: 0.0877 - val_mae: 0.2129 - val_mse: 0.0877\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 167us/sample - loss: 0.1929 - mae: 0.2615 - mse: 0.1929 - val_loss: 0.0956 - val_mae: 0.2230 - val_mse: 0.0956\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 190us/sample - loss: 0.1759 - mae: 0.2592 - mse: 0.1759 - val_loss: 0.0884 - val_mae: 0.2200 - val_mse: 0.0884\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.2060 - mae: 0.2590 - mse: 0.2060 - val_loss: 0.0900 - val_mae: 0.2097 - val_mse: 0.0900\n",
            "Epoch 21/200\n",
            "1022/1022 [==============================] - 0s 182us/sample - loss: 0.2540 - mae: 0.2722 - mse: 0.2540 - val_loss: 0.1076 - val_mae: 0.2342 - val_mse: 0.1076\n",
            "Epoch 22/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.1720 - mae: 0.2576 - mse: 0.1720 - val_loss: 0.0918 - val_mae: 0.2193 - val_mse: 0.0918\n",
            "Epoch 23/200\n",
            "1022/1022 [==============================] - 0s 171us/sample - loss: 0.1591 - mae: 0.2554 - mse: 0.1591 - val_loss: 0.1257 - val_mae: 0.2610 - val_mse: 0.1257\n",
            "Epoch 24/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.2329 - mae: 0.2621 - mse: 0.2329 - val_loss: 0.1103 - val_mae: 0.2492 - val_mse: 0.1103\n",
            "Epoch 25/200\n",
            "1022/1022 [==============================] - 0s 181us/sample - loss: 0.1848 - mae: 0.2533 - mse: 0.1848 - val_loss: 0.1188 - val_mae: 0.2471 - val_mse: 0.1188\n",
            "Epoch 26/200\n",
            "1022/1022 [==============================] - 0s 176us/sample - loss: 0.1920 - mae: 0.2553 - mse: 0.1920 - val_loss: 0.0995 - val_mae: 0.2280 - val_mse: 0.0995\n",
            "Epoch 27/200\n",
            "1022/1022 [==============================] - 0s 183us/sample - loss: 0.1816 - mae: 0.2491 - mse: 0.1816 - val_loss: 0.1036 - val_mae: 0.2346 - val_mse: 0.1036\n",
            "Temps d'entrainement 5.670990467071533 seconds ---\n",
            "Predicting house prices model network 32 * 32 * 1 with Callback\n",
            "Regression metrics for train data\n",
            "     max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  289243.4375         17987.939862        7.624297e+08  0.888877\n",
            "Regression metrics for test data\n",
            "      max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  179981.65625         19435.031625        7.105122e+08    0.8566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFXGsMM94vgm",
        "colab_type": "text"
      },
      "source": [
        "On arrive à une conclusion identique que l'architecture 64 par 64 avec une limitation du surapprentissage grâce aux paramètres DropOut sur les couches intermédiaires."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6eVf3ai3x5Z",
        "colab_type": "text"
      },
      "source": [
        "### Modèle avec 4 couches cachées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srEVRS1IxeSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "292fd077-2c5a-47f7-f25c-19ef07502b63"
      },
      "source": [
        "TrainingNetwork(model_32_16_8_4_1, str(32) +\" * \" + str(16) + \" * \" + str(8) + \" * \" + str(4)  + \" * 1\", callback=True)\n",
        "PredictionAndEvaluationNetwork(model_32_16_8_4_1,str(32) +\" * \" + str(16) + \" * \" + str(8) + \" * \" + str(4)  + \" * 1\", callback=True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model network 32 * 16 * 8 * 4 * 1 with Callback\n",
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 833us/sample - loss: 0.8091 - mae: 0.5358 - mse: 0.8091 - val_loss: 0.4549 - val_mae: 0.4056 - val_mse: 0.4549\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 191us/sample - loss: 0.6863 - mae: 0.4591 - mse: 0.6863 - val_loss: 0.3954 - val_mae: 0.3724 - val_mse: 0.3954\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 197us/sample - loss: 0.5845 - mae: 0.4104 - mse: 0.5845 - val_loss: 0.3097 - val_mae: 0.3369 - val_mse: 0.3097\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 194us/sample - loss: 0.4023 - mae: 0.3473 - mse: 0.4023 - val_loss: 0.1775 - val_mae: 0.2743 - val_mse: 0.1775\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 186us/sample - loss: 0.2558 - mae: 0.2742 - mse: 0.2558 - val_loss: 0.1195 - val_mae: 0.2355 - val_mse: 0.1195\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 202us/sample - loss: 0.2018 - mae: 0.2373 - mse: 0.2018 - val_loss: 0.0926 - val_mae: 0.2136 - val_mse: 0.0926\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 198us/sample - loss: 0.1777 - mae: 0.2184 - mse: 0.1777 - val_loss: 0.0863 - val_mae: 0.2083 - val_mse: 0.0863\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 202us/sample - loss: 0.1649 - mae: 0.2048 - mse: 0.1649 - val_loss: 0.0813 - val_mae: 0.2043 - val_mse: 0.0813\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 194us/sample - loss: 0.1491 - mae: 0.1903 - mse: 0.1491 - val_loss: 0.0770 - val_mae: 0.2015 - val_mse: 0.0770\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 188us/sample - loss: 0.1431 - mae: 0.1840 - mse: 0.1431 - val_loss: 0.0711 - val_mae: 0.1920 - val_mse: 0.0711\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 197us/sample - loss: 0.1388 - mae: 0.1770 - mse: 0.1388 - val_loss: 0.0673 - val_mae: 0.1823 - val_mse: 0.0673\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 189us/sample - loss: 0.1317 - mae: 0.1725 - mse: 0.1317 - val_loss: 0.0660 - val_mae: 0.1830 - val_mse: 0.0660\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 185us/sample - loss: 0.1268 - mae: 0.1611 - mse: 0.1268 - val_loss: 0.0663 - val_mae: 0.1829 - val_mse: 0.0663\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 195us/sample - loss: 0.1197 - mae: 0.1574 - mse: 0.1197 - val_loss: 0.0789 - val_mae: 0.2022 - val_mse: 0.0789\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 187us/sample - loss: 0.1169 - mae: 0.1522 - mse: 0.1169 - val_loss: 0.0894 - val_mae: 0.2131 - val_mse: 0.0894\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 207us/sample - loss: 0.1143 - mae: 0.1497 - mse: 0.1143 - val_loss: 0.0655 - val_mae: 0.1817 - val_mse: 0.0655\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 188us/sample - loss: 0.1095 - mae: 0.1460 - mse: 0.1095 - val_loss: 0.0646 - val_mae: 0.1798 - val_mse: 0.0646\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 197us/sample - loss: 0.1045 - mae: 0.1427 - mse: 0.1045 - val_loss: 0.0733 - val_mae: 0.1932 - val_mse: 0.0733\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 199us/sample - loss: 0.1018 - mae: 0.1398 - mse: 0.1018 - val_loss: 0.0700 - val_mae: 0.1869 - val_mse: 0.0700\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 193us/sample - loss: 0.0965 - mae: 0.1343 - mse: 0.0965 - val_loss: 0.0649 - val_mae: 0.1797 - val_mse: 0.0649\n",
            "Epoch 21/200\n",
            "1022/1022 [==============================] - 0s 202us/sample - loss: 0.0960 - mae: 0.1352 - mse: 0.0960 - val_loss: 0.0646 - val_mae: 0.1785 - val_mse: 0.0646\n",
            "Epoch 22/200\n",
            "1022/1022 [==============================] - 0s 198us/sample - loss: 0.0882 - mae: 0.1256 - mse: 0.0882 - val_loss: 0.0696 - val_mae: 0.1862 - val_mse: 0.0696\n",
            "Epoch 23/200\n",
            "1022/1022 [==============================] - 0s 191us/sample - loss: 0.0901 - mae: 0.1336 - mse: 0.0901 - val_loss: 0.0683 - val_mae: 0.1827 - val_mse: 0.0683\n",
            "Epoch 24/200\n",
            "1022/1022 [==============================] - 0s 220us/sample - loss: 0.0832 - mae: 0.1223 - mse: 0.0832 - val_loss: 0.0722 - val_mae: 0.1888 - val_mse: 0.0722\n",
            "Epoch 25/200\n",
            "1022/1022 [==============================] - 0s 194us/sample - loss: 0.0810 - mae: 0.1241 - mse: 0.0810 - val_loss: 0.0745 - val_mae: 0.1912 - val_mse: 0.0745\n",
            "Epoch 26/200\n",
            "1022/1022 [==============================] - 0s 211us/sample - loss: 0.0785 - mae: 0.1200 - mse: 0.0785 - val_loss: 0.0700 - val_mae: 0.1843 - val_mse: 0.0700\n",
            "Epoch 27/200\n",
            "1022/1022 [==============================] - 0s 184us/sample - loss: 0.0790 - mae: 0.1202 - mse: 0.0790 - val_loss: 0.0705 - val_mae: 0.1853 - val_mse: 0.0705\n",
            "Temps d'entrainement 6.1833176612854 seconds ---\n",
            "Predicting house prices model network 32 * 16 * 8 * 4 * 1 with Callback\n",
            "Regression metrics for train data\n",
            "     max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  376963.0625          8323.523781        4.531924e+08  0.933948\n",
            "Regression metrics for test data\n",
            "   max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0   128811.5         15350.462043        4.839954e+08  0.902317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0A8jaJ_7GW-",
        "colab_type": "text"
      },
      "source": [
        "Le résultat de cette architecture 4 couches expose toujours du surapprentissage mais dans une mesure moindre que les archictectures 2 couches avec 32 ou 64 neurones sans dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsN84J6P6KNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "4e155e7f-826f-4143-b724-9f9c2277b26e"
      },
      "source": [
        "print(\"Prise en compte du dropout dans le training dans les couches cachées avec rate = 5%\")\n",
        "TrainingNetwork(model_32_16_8_4_1_DropOut, str(32) +\" * \" + str(16) + \" * \" + str(8) + \" * \" + str(4)  + \" * 1\", callback=True)\n",
        "PredictionAndEvaluationNetwork(model_32_16_8_4_1_DropOut,str(32) +\" * \" + str(16) + \" * \" + str(8) + \" * \" + str(4)  + \" * 1\", callback=True)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prise en compte du dropout dans le training dans les couches cachées avec rate = 5%\n",
            "Training model network 32 * 16 * 8 * 4 * 1 with Callback\n",
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 1ms/sample - loss: 0.6462 - mae: 0.5931 - mse: 0.6462 - val_loss: 0.2386 - val_mae: 0.3626 - val_mse: 0.2386\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 199us/sample - loss: 0.3453 - mae: 0.3838 - mse: 0.3453 - val_loss: 0.1386 - val_mae: 0.2539 - val_mse: 0.1386\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 220us/sample - loss: 0.3233 - mae: 0.3394 - mse: 0.3233 - val_loss: 0.1160 - val_mae: 0.2270 - val_mse: 0.1160\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 200us/sample - loss: 0.3028 - mae: 0.3309 - mse: 0.3028 - val_loss: 0.1044 - val_mae: 0.2267 - val_mse: 0.1044\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 199us/sample - loss: 0.3277 - mae: 0.3196 - mse: 0.3277 - val_loss: 0.1090 - val_mae: 0.2203 - val_mse: 0.1090\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 201us/sample - loss: 0.2372 - mae: 0.2934 - mse: 0.2372 - val_loss: 0.0850 - val_mae: 0.2011 - val_mse: 0.0850\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 204us/sample - loss: 0.2397 - mae: 0.2829 - mse: 0.2397 - val_loss: 0.0862 - val_mae: 0.1938 - val_mse: 0.0862\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 193us/sample - loss: 0.2565 - mae: 0.2802 - mse: 0.2565 - val_loss: 0.1002 - val_mae: 0.2196 - val_mse: 0.1002\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 220us/sample - loss: 0.3028 - mae: 0.2891 - mse: 0.3028 - val_loss: 0.0947 - val_mae: 0.1981 - val_mse: 0.0947\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 194us/sample - loss: 0.2267 - mae: 0.2712 - mse: 0.2267 - val_loss: 0.0871 - val_mae: 0.1988 - val_mse: 0.0871\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 208us/sample - loss: 0.2230 - mae: 0.2571 - mse: 0.2230 - val_loss: 0.0781 - val_mae: 0.1813 - val_mse: 0.0781\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 189us/sample - loss: 0.2172 - mae: 0.2494 - mse: 0.2172 - val_loss: 0.0837 - val_mae: 0.1890 - val_mse: 0.0837\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 209us/sample - loss: 0.2181 - mae: 0.2502 - mse: 0.2181 - val_loss: 0.0873 - val_mae: 0.1888 - val_mse: 0.0873\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 209us/sample - loss: 0.2046 - mae: 0.2402 - mse: 0.2046 - val_loss: 0.0890 - val_mae: 0.2008 - val_mse: 0.0890\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 200us/sample - loss: 0.1845 - mae: 0.2454 - mse: 0.1845 - val_loss: 0.1071 - val_mae: 0.2178 - val_mse: 0.1071\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 195us/sample - loss: 0.2165 - mae: 0.2431 - mse: 0.2165 - val_loss: 0.0874 - val_mae: 0.1869 - val_mse: 0.0874\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 193us/sample - loss: 0.1709 - mae: 0.2315 - mse: 0.1709 - val_loss: 0.0897 - val_mae: 0.1983 - val_mse: 0.0897\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 200us/sample - loss: 0.1682 - mae: 0.2280 - mse: 0.1682 - val_loss: 0.0893 - val_mae: 0.1948 - val_mse: 0.0893\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 218us/sample - loss: 0.2008 - mae: 0.2342 - mse: 0.2008 - val_loss: 0.0962 - val_mae: 0.2107 - val_mse: 0.0962\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 201us/sample - loss: 0.1382 - mae: 0.2113 - mse: 0.1382 - val_loss: 0.0915 - val_mae: 0.1959 - val_mse: 0.0915\n",
            "Epoch 21/200\n",
            "1022/1022 [==============================] - 0s 202us/sample - loss: 0.1576 - mae: 0.2216 - mse: 0.1576 - val_loss: 0.0878 - val_mae: 0.1945 - val_mse: 0.0878\n",
            "Temps d'entrainement 5.282951593399048 seconds ---\n",
            "Predicting house prices model network 32 * 16 * 8 * 4 * 1 with Callback\n",
            "Regression metrics for train data\n",
            "      max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  286010.96875         12338.197342        5.263189e+08   0.92329\n",
            "Regression metrics for test data\n",
            "    max_error  mean_absolute_error  mean_squared_error  r2_score\n",
            "0  194475.125         16110.684932        6.021313e+08  0.878474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-SXPrDkr4RC",
        "colab_type": "text"
      },
      "source": [
        "Le dropout avec 5% sur les couches intermédiaires diminue le surapprentissage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJpavCzgsZ58",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion sur les réseaux de neurones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60wXl9kosg0W",
        "colab_type": "text"
      },
      "source": [
        "* Différentes architectures peuvent être testées avec plus ou moins de couches cachées, le nombre de neurones par couche, du tuning fin sur des paramètres comme le dropout ou encore introduire des régularisations sur les données. \n",
        "* Dans le cas présent, ma recommandation serait d'utiliser l'architecture 4 couches avec dropout à 5% sur les couches cachées pour diminuer le surapprentissage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jas_SHcn9JRa",
        "colab_type": "text"
      },
      "source": [
        "# Soumission sur le test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "105xRcFP9JRa",
        "colab_type": "text"
      },
      "source": [
        "On applique les différents modèles en arrondissant les résultats avec uniquement une décimale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iL8GIB99JRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictionWithLinearRegression = np.around(Yscaler.inverse_transform(clfRegLinear.predict(df_test)), decimals = 1)\n",
        "predictionWithLassoRegression = np.around(Yscaler.inverse_transform(clfLasso.predict(df_test)), decimals = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg1AoCGb9JRd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "On construit un dataframe avec l'id et les résultats des différents modèles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49iwLKoR9JRe",
        "colab_type": "code",
        "outputId": "d06783bf-2b03-4728-d700-05e09f94bc84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "submission = pd.DataFrame({'Id':df_test['Id'],'Linear Reg':predictionWithLinearRegression, 'Lasso Reg':predictionWithLassoRegression})\n",
        "\n",
        "#Visualize the first 5 rows\n",
        "submission.head(10)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Linear Reg</th>\n",
              "      <th>Lasso Reg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>139589.9</td>\n",
              "      <td>135235.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>134848.0</td>\n",
              "      <td>142465.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>169168.0</td>\n",
              "      <td>172334.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>183926.4</td>\n",
              "      <td>186485.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>216373.7</td>\n",
              "      <td>212879.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1466</td>\n",
              "      <td>159265.1</td>\n",
              "      <td>162479.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1467</td>\n",
              "      <td>178109.9</td>\n",
              "      <td>172909.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1468</td>\n",
              "      <td>147748.3</td>\n",
              "      <td>152326.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1469</td>\n",
              "      <td>199902.4</td>\n",
              "      <td>201835.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1470</td>\n",
              "      <td>129195.7</td>\n",
              "      <td>127526.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id  Linear Reg  Lasso Reg\n",
              "0  1461    139589.9   135235.7\n",
              "1  1462    134848.0   142465.8\n",
              "2  1463    169168.0   172334.5\n",
              "3  1464    183926.4   186485.0\n",
              "4  1465    216373.7   212879.4\n",
              "5  1466    159265.1   162479.6\n",
              "6  1467    178109.9   172909.3\n",
              "7  1468    147748.3   152326.8\n",
              "8  1469    199902.4   201835.9\n",
              "9  1470    129195.7   127526.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z39BnmBB9JRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filename = \"https://raw.githubusercontent.com/anthonymoisan/DeepLearningPredictHousePrices/master/output/HousePricesPrediction.csv\"\n",
        "#submission.to_csv(filename, index=False, encoding=\"UTF-8\", mode = \"wb\")\n",
        "#print('Sauvegarde du fichier : ' filename)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}